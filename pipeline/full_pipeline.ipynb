{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73e3a524",
   "metadata": {},
   "source": [
    "# IG to Test Kit FULL pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5d267b",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de19ee6",
   "metadata": {},
   "source": [
    "### Importing Notebooks as Modules (from the [Jupyter Notebook Documentation](https://jupyter-notebook.readthedocs.io/en/4.x/examples/Notebook/rstversions/Importing%20Notebooks.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9fc5ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import json\n",
    "import llm_utils\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de7a6cc",
   "metadata": {},
   "source": [
    "## Initializing LLM Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ead91a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(llm_utils)\n",
    "llm_clients = llm_utils.LLMApiClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c39d130b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claude': <anthropic.Anthropic at 0x1153f1ac0>,\n",
       " 'gemini': genai.GenerativeModel(\n",
       "     model_name='models/gemini-2.5-pro',\n",
       "     generation_config={'max_output_tokens': 8192, 'temperature': 0.3},\n",
       "     safety_settings={<HarmCategory.HARM_CATEGORY_HARASSMENT: 7>: <HarmBlockThreshold.BLOCK_NONE: 4>, <HarmCategory.HARM_CATEGORY_HATE_SPEECH: 8>: <HarmBlockThreshold.BLOCK_NONE: 4>, <HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: 9>: <HarmBlockThreshold.BLOCK_NONE: 4>, <HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: 10>: <HarmBlockThreshold.BLOCK_NONE: 4>},\n",
       "     tools=None,\n",
       "     system_instruction=None,\n",
       "     cached_content=None\n",
       " ),\n",
       " 'gpt': <openai.OpenAI at 0x11501a9f0>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_clients.clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6d80d1",
   "metadata": {},
   "source": [
    "## Text Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08717e1c",
   "metadata": {},
   "source": [
    "### HTML to Markdown Conversion Using Markdownify (Langchain Tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e9d960b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import HTML_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac0340e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|##########| 7/7 [00:00<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: index.md\n",
      "Created: ChangeHistory.md\n",
      "Created: examples.md\n",
      "Created: implementation.md\n",
      "Created: profiles.md\n",
      "Created: artifacts.md\n",
      "Created: CapabilityStatement_plan_net.md\n"
     ]
    }
   ],
   "source": [
    "urls = [\n",
    "    \"https://hl7.org/fhir/us/davinci-pdex-plan-net/index.html\",\n",
    "    \"https://hl7.org/fhir/us/davinci-pdex-plan-net/ChangeHistory.html\",\n",
    "    \"https://hl7.org/fhir/us/davinci-pdex-plan-net/examples.html\",\n",
    "    \"https://hl7.org/fhir/us/davinci-pdex-plan-net/implementation.html\",\n",
    "    \"https://hl7.org/fhir/us/davinci-pdex-plan-net/profiles.html\",\n",
    "    \"https://hl7.org/fhir/us/davinci-pdex-plan-net/artifacts.html\",\n",
    "    \"https://hl7.org/fhir/us/davinci-pdex-plan-net/CapabilityStatement-plan-net.html\"\n",
    "]\n",
    "\n",
    "HTML_extractor.convert_urls_to_markdown(urls, output_dir=\"text_extraction/PlanNet/site/markdown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0108ece",
   "metadata": {},
   "source": [
    "### Markdown Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aec7806b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 markdown files in checkpoints/text_extraction/PlanNet/site/markdown\n",
      "Cleaned and saved: checkpoints/post_processing/implementation.md\n",
      "Cleaned and saved: checkpoints/post_processing/examples.md\n",
      "Cleaned and saved: checkpoints/post_processing/profiles.md\n",
      "Cleaned and saved: checkpoints/post_processing/ChangeHistory.md\n",
      "Cleaned and saved: checkpoints/post_processing/artifacts.md\n",
      "Cleaned and saved: checkpoints/post_processing/index.md\n",
      "Cleaned and saved: checkpoints/post_processing/CapabilityStatement_plan_net.md\n",
      "\n",
      "Processing complete: 7 files successfully cleaned, 0 failed\n"
     ]
    }
   ],
   "source": [
    "import markdown_cleaner\n",
    "markdown_cleaner.process_directory(\"checkpoints/text_extraction/PlanNet/site/markdown\", \"checkpoints/post_processing/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3fa2d1",
   "metadata": {},
   "source": [
    "## Requirements Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0566ab",
   "metadata": {},
   "source": [
    "### Prompt-based Requirement Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d4e5a8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reqs_extraction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m importlib.reload(\u001b[43mreqs_extraction\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'reqs_extraction' is not defined"
     ]
    }
   ],
   "source": [
    "importlib.reload(reqs_extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7fd5bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Current working directory: /Users/ceadams/Documents/onclaive/onclaive/pipeline\n",
      "INFO:root:Project root: /Users/ceadams/Documents/onclaive/onclaive\n",
      "INFO:root:Prompt environment set up at: /Users/ceadams/Documents/onclaive/onclaive/prompts\n",
      "INFO:root:Using prompts directory: /Users/ceadams/Documents/onclaive/onclaive/prompts\n",
      "INFO:root:Requirements extraction prompt: /Users/ceadams/Documents/onclaive/onclaive/prompts/requirements_extraction.md\n"
     ]
    }
   ],
   "source": [
    "import reqs_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31999d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Found markdown directory at /Users/ceadams/Documents/onclaive/onclaive/full-ig/markdown_safety\n",
      "INFO:root:Found 2 markdown files\n",
      "INFO:root:Processing with gemini...\n",
      "INFO:root:Starting processing with gemini on directory: /Users/ceadams/Documents/onclaive/onclaive/full-ig/markdown_safety\n",
      "INFO:root:Found 2 markdown files:\n",
      "INFO:root:  - CapabilityStatement_plan_net.md\n",
      "INFO:root:  - StructureDefinition-qualification-definitions.md\n",
      "INFO:root:Organized 2 files into 2 processing groups\n",
      "INFO:root:Processing single file: CapabilityStatement_plan_net.md\n",
      "INFO:root:Split CapabilityStatement_plan_net.md into 1 chunks using dynamic sizing\n",
      "INFO:root:Processing chunk 1/1 of CapabilityStatement_plan_net.md\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Implementation Guide with Gemini...\n",
      "This may take several minutes depending on the size of the Implementation Guide.\n",
      "\n",
      "⚠️  SAFETY FILTER BLOCKED CONTENT #1\n",
      "============================================================\n",
      "BLOCKED CONTENT SAMPLE:\n",
      "System: You are a Healthcare Integration Test Engineer with expertise in INCOSE Systems Engineering standards, analyzing FHIR \n",
      "    Implementation Guide content to identify and format testable requirements following INCOSE specifications.\n",
      "\n",
      "User: [{'parts': [{'text': '# ABOUT THIS TASK\\nYou are analyzing chunk 1 of 1 from a FHIR Implementation Guide. Your task is to:\\n1. Extract specific, testable requirements\\n2. Format them according to INCOSE Systems Engineering standards\\n3. Create requirement...\n",
      "============================================================\n",
      "Skipping this chunk and continuing...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Processing single file: StructureDefinition-qualification-definitions.md\n",
      "INFO:root:Split StructureDefinition-qualification-definitions.md into 1 chunks using dynamic sizing\n",
      "INFO:root:Processing chunk 1/1 of StructureDefinition-qualification-definitions.md\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚠️  SAFETY FILTER BLOCKED CONTENT #2\n",
      "============================================================\n",
      "BLOCKED CONTENT SAMPLE:\n",
      "System: You are a Healthcare Integration Test Engineer with expertise in INCOSE Systems Engineering standards, analyzing FHIR \n",
      "    Implementation Guide content to identify and format testable requirements following INCOSE specifications.\n",
      "\n",
      "User: [{'parts': [{'text': '# ABOUT THIS TASK\\nYou are analyzing chunk 1 of 1 from a FHIR Implementation Guide. Your task is to:\\n1. Extract specific, testable requirements\\n2. Format them according to INCOSE Systems Engineering standards\\n3. Create requirement...\n",
      "============================================================\n",
      "Skipping this chunk and continuing...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Completed processing 2 files\n",
      "INFO:root:Generated requirements document saved to checkpoints/requirements_extraction/markdown/gemini_reqs_list_v1_20250723_150027.md\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Processing complete!\n",
      "Generated requirements document: checkpoints/requirements_extraction/markdown/gemini_reqs_list_v1_20250723_150027.md\n",
      "Processed 2 files\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "reqs_extraction.run_requirements_extractor(\n",
    "    '/Users/ceadams/Documents/onclaive/onclaive/full-ig/markdown_safety', \n",
    "    'checkpoints/requirements_extraction/markdown', \n",
    "    'gemini', \n",
    "    llm_clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d402ce7",
   "metadata": {},
   "source": [
    "### RAG-based Requirement Extraction\n",
    "\n",
    "This extraction requirement extraction method differs from the first in that, as a part of the creation of its prompt, it performs a semantic search on example sections of FHIR IG text and the human-generated requirements that were produced in reference to those sections of text to find the most similar section(s) of FHIR IG text in the database and their associated requirement(s). Those sets of IG text and requirement(s) are then supplied to the LLM as few-shot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15d61585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rag_reqs_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8c6bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 of 2\r"
     ]
    }
   ],
   "source": [
    "importlib.reload(rag_reqs_extraction)\n",
    "rag_reqs_extraction.full_pass(llm_clients, 'claude', \"checkpoints/post_processing/\", \"checkpoints/requirements_extraction/RAG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2ccc40",
   "metadata": {},
   "source": [
    "## Requirement Downselection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78226f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair 53824 of 53824\r"
     ]
    }
   ],
   "source": [
    "import requirement_downselect\n",
    "importlib.reload(requirement_downselect)\n",
    "requirement_downselect.full_pass(\n",
    "    md_files=[\"checkpoints/requirements_extraction/claude_reqs_list_v1_20250429_081756.md\"],\n",
    "    rag_files=[\"checkpoints/requirements_extraction/RAG/plan_net_reqs.json\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669a69ed",
   "metadata": {},
   "source": [
    "## Test Plan Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ee31b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "llm_clients.logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8be0d386",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 14:02:01,909 - root - INFO - Prompt environment set up at: /Users/ceadams/Documents/onclaive/onclaive/prompts\n",
      "2025-07-01 14:02:01,910 - llm_utils - INFO - Starting test plan generation with gemini for Plan-Net IG\n",
      "2025-07-01 14:02:01,911 - llm_utils - INFO - Parsed 5 requirements from /Users/ceadams/Documents/onclaive/onclaive/reqs_extraction/revised_reqs_output/small-plan-net-requirements-v3.md\n",
      "2025-07-01 14:02:01,912 - llm_utils - INFO - Parsed capability statement from /Users/ceadams/Documents/onclaive/onclaive/full-ig/markdown7_cleaned/CapabilityStatement_plan_net.md\n",
      "2025-07-01 14:02:01,913 - llm_utils - INFO - Identifying group for requirement REQ-34 using gemini...\n",
      "2025-07-01 14:02:12,576 - llm_utils - INFO - Identifying group for requirement REQ-35 using gemini...\n",
      "2025-07-01 14:02:22,932 - llm_utils - INFO - Identifying group for requirement REQ-36 using gemini...\n",
      "2025-07-01 14:02:37,736 - llm_utils - INFO - Identifying group for requirement REQ-37 using gemini...\n",
      "2025-07-01 14:02:51,821 - llm_utils - INFO - Identifying group for requirement REQ-38 using gemini...\n",
      "2025-07-01 14:03:06,100 - llm_utils - INFO - Requirements grouped into 5 categories\n",
      "2025-07-01 14:03:06,101 - llm_utils - INFO - Group 'Organization': 1 requirements\n",
      "2025-07-01 14:03:06,102 - llm_utils - INFO - Group 'PractitionerRole': 1 requirements\n",
      "2025-07-01 14:03:06,102 - llm_utils - INFO - Group 'Plan-Net OrganizationAffiliation': 1 requirements\n",
      "2025-07-01 14:03:06,102 - llm_utils - INFO - Group 'Network': 1 requirements\n",
      "2025-07-01 14:03:06,103 - llm_utils - INFO - Group 'Plan-Net Organization': 1 requirements\n",
      "2025-07-01 14:03:06,103 - llm_utils - INFO - Processing requirement for group 'Network': REQ-37\n",
      "2025-07-01 14:03:06,103 - llm_utils - INFO - Generating test specification for REQ-37 using gemini...\n",
      "2025-07-01 14:03:55,285 - llm_utils - INFO - Processing requirement for group 'Organization': REQ-34\n",
      "2025-07-01 14:03:55,286 - llm_utils - INFO - Generating test specification for REQ-34 using gemini...\n",
      "2025-07-01 14:04:57,441 - llm_utils - INFO - Processing requirement for group 'Plan-Net Organization': REQ-38\n",
      "2025-07-01 14:04:57,443 - llm_utils - INFO - Generating test specification for REQ-38 using gemini...\n",
      "2025-07-01 14:05:18,968 - llm_utils - INFO - Processing requirement for group 'Plan-Net OrganizationAffiliation': REQ-36\n",
      "2025-07-01 14:05:18,969 - llm_utils - INFO - Generating test specification for REQ-36 using gemini...\n",
      "2025-07-01 14:06:10,609 - llm_utils - INFO - Processing requirement for group 'PractitionerRole': REQ-35\n",
      "2025-07-01 14:06:10,611 - llm_utils - INFO - Generating test specification for REQ-35 using gemini...\n",
      "2025-07-01 14:06:50,911 - llm_utils - INFO - Consolidated test plan saved to checkpoints/testplan_generation/gemini_test_plan_20250701_140201.md\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated test plan with improved capability parsing: checkpoints/testplan_generation/gemini_test_plan_20250701_140201.md\n"
     ]
    }
   ],
   "source": [
    "import req_to_testplan\n",
    "importlib.reload(req_to_testplan)\n",
    "\n",
    "result = req_to_testplan.generate_consolidated_test_plan(\n",
    "    llm_clients,\n",
    "    'gemini',  # or 'gemini' or 'gpt'\n",
    "    llm_clients.logger,\n",
    "    \"/Users/ceadams/Documents/onclaive/onclaive/reqs_extraction/revised_reqs_output/small-plan-net-requirements-v3.md\",\n",
    "    \"/Users/ceadams/Documents/onclaive/onclaive/full-ig/markdown7_cleaned/CapabilityStatement_plan_net.md\",\n",
    "    \"Plan-Net IG\",\n",
    "    output_dir='checkpoints/testplan_generation'\n",
    ")\n",
    "\n",
    "print(f\"Generated test plan with improved capability parsing: {result['test_plan_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54914262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Capability Statement Analysis:\n",
      "- Found 8 resources: ['Endpoint', 'HealthcareService', 'InsurancePlan', 'Location', 'Organization', 'OrganizationAffiliation', 'Practitioner', 'PractitionerRole']\n",
      "- General capabilities text length: 1113 characters\n"
     ]
    }
   ],
   "source": [
    "capability_statement = req_to_testplan.parse_capability_statement_by_chunks(\n",
    "    \"/Users/ceadams/Documents/onclaive/onclaive/full-ig/markdown7_cleaned/CapabilityStatement_plan_net.md\"\n",
    ")\n",
    "\n",
    "print(f\"\\nCapability Statement Analysis:\")\n",
    "print(f\"- Found {len(capability_statement['resource_list'])} resources: {capability_statement['resource_list']}\")\n",
    "print(f\"- General capabilities text length: {len(capability_statement['general_capabilities'])} characters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cc38ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample requirement matching:\n",
      "- Relevant capability info length: 6082 characters\n",
      "- Preview: ### Applicable Capability Statement Information\n",
      "\n",
      "#### Relevant Resource Capabilities\n",
      "\n",
      "#### Location\n",
      "\n",
      "Conformance Expectation: **SHALL**\n",
      "\n",
      "Supported Profiles:\n",
      "\n",
      " [Plan\\-Net Location](StructureDefinition-plannet-Location.html)\n",
      "\n",
      "Reference Policy: `resolves`\n",
      "\n",
      "Profile Interaction Summary:\n",
      "\n",
      "* **SHALL** support \n",
      " `search-type`, \n",
      " `read`.\n",
      "* **SHOULD** support \n",
      " `vread`.\n",
      "\n",
      "Fetch and Search Criteria:\n",
      "\n",
      "* A Server **SHALL** be capable of returning a Location resource using:\n",
      "\n",
      "`GET [base]/Location/[id]`\n",
      "\n",
      "* A Server **SHOULD** be capable of returning a Location resource using:\n",
      "\n",
      "`GET [base]/Location/[id]/_history/vid`\n",
      "\n",
      " * A Server **SHALL** be capable of supporting the following \\_includes:\n",
      "\n",
      " Location:endpoint \\- `GET [base]/Location?[parameter=value]&_include=Location:endpoint`  \n",
      "\n",
      " Location:organization \\- `GET [base]/Location?[parameter=value]&_include=Location:organization`  \n",
      "\n",
      " Location:partof \\- `GET [base]/Location?[parameter=value]&_include=Location:partof`\n",
      "\n",
      " * A Server **SHALL** be capable of supporting the following \\_revincludes:\n",
      "\n",
      " HealthcareService:location \\- `GET [base]/Location?[parameter=value]&_revinclude=HealthcareService:location`  \n",
      "\n",
      " InsurancePlan:coverage\\-area \\- `GET [base]/Location?[parameter=value]&_revinclude=InsurancePlan:coverage-area`  \n",
      "\n",
      " OrganizationAffiliation:location \\- `GET [base]/Location?[parameter=value]&_revinclude=OrganizationAffiliation:location`  \n",
      "\n",
      " PractitionerRole:location \\- `GET [base]/Location?[parameter=value]&_revinclude=PractitionerRole:location`\n",
      "\n",
      "Search Parameter Summary:\n",
      "\n",
      "| Conformance | Parameter | Type | Example |\n",
      "| --- | --- | --- | --- |\n",
      "| **SHALL** | [partof](SearchParameter-location-partof.html) | reference | `GET [base]/Location?partof=[partof]` |\n",
      "| **SHALL** | [organization](SearchParameter-location-organization.html) | reference | `GET [base]/Location?organization=[organization]` |\n",
      "| **SHALL** | [endpoint](SearchParameter-location-endpoint.html) | reference | `GET [base]/Location?endpoint=[endpoint]` |\n",
      "| **SHALL** | [address\\-city](SearchParameter-location-address-city.html) | string | `GET [base]/Location?address-city=[address-city]` |\n",
      "| **SHALL** | [address\\-state](SearchParameter-location-address-state.html) | string | `GET [base]/Location?address-state=[address-state]` |\n",
      "| **SHALL** | [address\\-postalcode](SearchParameter-location-address-postalcode.html) | string | `GET [base]/Location?address-postalcode=[address-postalcode]` |\n",
      "| **SHALL** | [address](SearchParameter-location-address.html) | string | `GET [base]/Location?address=[address]` |\n",
      "| **SHALL** | [type](SearchParameter-location-type.html) | token | `GET [base]/Location?type=[system]|[code]` |\n",
      "| **SHALL** | [\\_id](http://hl7.org/fhir/R4/search.html) | token | `GET [base]/Location?_id=[id]` |\n",
      "| **SHALL** | [\\_lastUpdated](http://hl7.org/fhir/R4/search.html) | date | `GET [base]/Location?_lastUpdated=[_lastUpdated]` |\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "#### Organization\n",
      "\n",
      "Conformance Expectation: **SHALL**\n",
      "\n",
      "Supported Profiles:\n",
      "\n",
      " [Plan\\-Net Network](StructureDefinition-plannet-Network.html), \n",
      "\n",
      " [Plan\\-Net Organization](StructureDefinition-plannet-Organization.html)\n",
      "\n",
      "Reference Policy: `resolves`\n",
      "\n",
      "Profile Interaction Summary:\n",
      "\n",
      "* **SHALL** support \n",
      " `search-type`, \n",
      " `read`.\n",
      "* **SHOULD** support \n",
      " `vread`.\n",
      "\n",
      "Fetch and Search Criteria:\n",
      "\n",
      "* A Server **SHALL** be capable of returning a Organization resource using:\n",
      "\n",
      "`GET [base]/Organization/[id]`\n",
      "\n",
      "* A Server **SHOULD** be capable of returning a Organization resource using:\n",
      "\n",
      "`GET [base]/Organization/[id]/_history/vid`\n",
      "\n",
      " * A Server **SHALL** be capable of supporting the following \\_includes:\n",
      "\n",
      " Organization:partof \\- `GET [base]/Organization?[parameter=value]&_include=Organization:partof`  \n",
      "\n",
      " Organization:endpoint \\- `GET [base]/Organization?[parameter=value]&_include=Organization:endpoint`  \n",
      "\n",
      " Organization:coverage\\-area \\- `GET [base]/Organization?[parameter=value]&_include=Organization:coverage-area`\n",
      "\n",
      " * A Server **SHALL** be capable of supporting the following \\_revincludes:\n",
      "\n",
      " Endpoint:organization \\- `GET [base]/Organization?[parameter=value]&_revinclude=Endpoint:organization`  \n",
      "\n",
      " HealthcareService:organization \\- `GET [base]/Organization?[parameter=value]&_revinclude=HealthcareService:organization`  \n",
      "\n",
      " InsurancePlan:administered\\-by \\- `GET [base]/Organization?[parameter=value]&_revinclude=InsurancePlan:administered-by`  \n",
      "\n",
      " InsurancePlan:owned\\-by \\- `GET [base]/Organization?[parameter=value]&_revinclude=InsurancePlan:owned-by`  \n",
      "\n",
      " OrganizationAffiliation:primary\\-organization \\- `GET [base]/Organization?[parameter=value]&_revinclude=OrganizationAffiliation:primary-organization`  \n",
      "\n",
      " PractitionerRole:organization \\- `GET [base]/Organization?[parameter=value]&_revinclude=PractitionerRole:organization`  \n",
      "\n",
      " PractitionerRole:network \\- `GET [base]/Organization?[parameter=value]&_revinclude=PractitionerRole:network`  \n",
      "\n",
      " OrganizationAffiliation:participating\\-organization \\- `GET [base]/Organization?[parameter=value]&_revinclude=OrganizationAffiliation:participating-organization`\n",
      "\n",
      "Search Parameter Summary:\n",
      "\n",
      "| Conformance | Parameter | Type | Example |\n",
      "| --- | --- | --- | --- |\n",
      "| **SHALL** | [partof](SearchParameter-organization-partof.html) | reference | `GET [base]/Organization?partof=[partof]` |\n",
      "| **SHALL** | [endpoint](SearchParameter-organization-endpoint.html) | reference | `GET [base]/Organization?endpoint=[endpoint]` |\n",
      "| **SHALL** | [address](SearchParameter-organization-address.html) | string | `GET [base]/Organization?address=[address]` |\n",
      "| **SHALL** | [name](SearchParameter-organization-name.html) | string | `GET [base]/Organization?name=[name]` |\n",
      "| **SHALL** | [\\_id](http://hl7.org/fhir/R4/search.html) | token | `GET [base]/Organization?_id=[id]` |\n",
      "| **SHALL** | [\\_lastUpdated](http://hl7.org/fhir/R4/search.html) | date | `GET [base]/Organization?_lastUpdated=[_lastUpdated]` |\n",
      "| **SHALL** | [type](SearchParameter-organization-type.html) | token | `GET [base]/Organization?type=[system]|[code]` |\n",
      "| **SHALL** | [coverage\\-area](SearchParameter-organization-coverage-area.html) | reference | `GET [base]/Organization?coverage-area=[coverage-area]` |\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "sample_requirement = {\n",
    "    'summary': 'Organization search by name',\n",
    "    'description': 'The Plan-Net design is based around the following types of searches: Organization by Name - Example: Montgomery Cardiology or CVS - Focal Resource and Field: Organization.name - Qualifications of Search: Location, network, specialty.',\n",
    "    'verification': 'Automatically testable',\n",
    "    'actor': 'Health Plan API'\n",
    "}\n",
    "\n",
    "relevant_info = req_to_testplan.extract_relevant_capability_chunks(sample_requirement, capability_statement)\n",
    "print(f\"\\nSample requirement matching:\")\n",
    "print(f\"- Relevant capability info length: {len(relevant_info)} characters\")\n",
    "print(f\"- Preview: {relevant_info}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54f6a62",
   "metadata": {},
   "source": [
    "### RAG Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbf87c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cf1f5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-02 13:55:41,483 - root - INFO - Prompt environment set up at: /Users/ceadams/Documents/onclaive/onclaive/prompts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing collection: capability_statements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-02 13:55:46,426 - backoff - ERROR - Giving up send_request(...) after 4 tries (requests.exceptions.SSLError: HTTPSConnectionPool(host='us.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)'))))\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# Set logging level to reduce noise\n",
    "import logging\n",
    "logging.getLogger(\"urllib3.connectionpool\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"backoff\").setLevel(logging.ERROR)\n",
    "\n",
    "import req_to_testplan_rag\n",
    "importlib.reload(req_to_testplan_rag)\n",
    "\n",
    "req_to_testplan_rag.clear_capability_collection(\"capability_statements\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a668d468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 12:24:19,465 - llm_utils - INFO - Starting test plan generation with gemini for Plan-Net IG\n",
      "2025-07-09 12:24:19,467 - llm_utils - INFO - Parsed 5 requirements from /Users/ceadams/Documents/onclaive/onclaive/reqs_extraction/revised_reqs_output/small-plan-net-requirements-v4.md\n",
      "2025-07-09 12:24:19,490 - req_to_testplan_rag - INFO - Using existing collection: capability_statements\n",
      "2025-07-09 12:24:19,494 - llm_utils - INFO - Initialized capability collection from ../full-ig/markdown7_cleaned/CapabilityStatement_plan_net.md\n",
      "2025-07-09 12:24:19,504 - llm_utils - INFO - Identifying group for requirement REQ-02 using gemini...\n",
      "2025-07-09 12:24:25,258 - backoff - ERROR - Giving up send_request(...) after 4 tries (requests.exceptions.SSLError: HTTPSConnectionPool(host='us.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)'))))\n",
      "2025-07-09 12:24:36,415 - llm_utils - INFO - Identifying group for requirement REQ-03 using gemini...\n",
      "2025-07-09 12:24:55,964 - llm_utils - INFO - Identifying group for requirement REQ-06 using gemini...\n",
      "2025-07-09 12:25:50,758 - llm_utils - INFO - Identifying group for requirement REQ-09 using gemini...\n",
      "2025-07-09 12:26:32,936 - llm_utils - INFO - Identifying group for requirement REQ-10 using gemini...\n",
      "2025-07-09 12:26:45,442 - llm_utils - INFO - Requirements grouped into 3 categories\n",
      "2025-07-09 12:26:45,443 - llm_utils - INFO - Group 'Plan-Net Endpoint': 3 requirements\n",
      "2025-07-09 12:26:45,444 - llm_utils - INFO - Group 'Network': 1 requirements\n",
      "2025-07-09 12:26:45,445 - llm_utils - INFO - Group 'General Requirements': 1 requirements\n",
      "2025-07-09 12:26:45,446 - llm_utils - INFO - Processing requirement for group 'General Requirements': REQ-09\n",
      "2025-07-09 12:26:45,447 - llm_utils - INFO - Generating test specification for REQ-09 using gemini...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Group: General Requirements (1 requirements)\n",
      "\n",
      "Processing REQ-09: Client processing of missing information indicators\n",
      "\n",
      "================================================================================\n",
      "RAG RETRIEVAL FOR REQ-09\n",
      "================================================================================\n",
      "Query: Client processing of missing information indicators \"Consumer App actors SHALL be able to process resource instances containing Must Support data elements asserting missing information.\" Application Actor FHIR SHALL\n",
      "Searching for 5 most relevant capability chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0982c25cad4a36b2981972d8e16369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 5 matching chunks:\n",
      "\n",
      "  Match 1 (distance: 1.0090609788894653):\n",
      "  Length: 802 chars\n",
      "  Preview: FHIR Major Section: ## Plan\\-Net CapabilityStatement\n",
      "\n",
      "* Implementation Guide Version: 1\\.0\\.0\n",
      "* FHIR...\n",
      "  ...local use cases and other contextual requirements.\n",
      "\n",
      "  Match 2 (distance: 1.1007232666015625):\n",
      "  Length: 3225 chars\n",
      "  Preview: FHIR Resource Detail: #### Organization\n",
      "\n",
      "Conformance Expectation: **SHALL**\n",
      "\n",
      "Supported Profiles:\n",
      "\n",
      " [...\n",
      "  ...Organization?coverage-area=[coverage-area]` |\n",
      "\n",
      "---\n",
      "\n",
      "  Match 3 (distance: 1.1312487125396729):\n",
      "  Length: 996 chars\n",
      "  Preview: FHIR Major Section: ## CapabilityStatement: Plan\\-Net CapabilityStatement\n",
      "\n",
      "| *Official URL*: http://...\n",
      "  ...openapi.json) \\| [Download](plan-net.openapi.json)\n",
      "\n",
      "  Match 4 (distance: 1.1321117877960205):\n",
      "  Length: 2302 chars\n",
      "  Preview: FHIR Resource Detail: #### InsurancePlan\n",
      "\n",
      "Conformance Expectation: **SHALL**\n",
      "\n",
      "Supported Profiles:\n",
      "\n",
      " ...\n",
      "  ... [base]/InsurancePlan?type=[system]|[code]` |\n",
      "\n",
      "---\n",
      "\n",
      "  Match 5 (distance: 1.1403684616088867):\n",
      "  Length: 2854 chars\n",
      "  Preview: FHIR Resource Detail: #### PractitionerRole\n",
      "\n",
      "Conformance Expectation: **SHALL**\n",
      "\n",
      "Supported Profiles:...\n",
      "  ...actitionerRole?_lastUpdated=[_lastUpdated]` |\n",
      "\n",
      "---\n",
      "================================================================================\n",
      "\n",
      "Sending request to GEMINI API...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 12:27:23,446 - llm_utils - INFO - Processing requirement for group 'Network': REQ-06\n",
      "2025-07-09 12:27:23,446 - llm_utils - INFO - Generating test specification for REQ-06 using gemini...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed test specification for REQ-09\n",
      "\n",
      "Processing Group: Network (1 requirements)\n",
      "\n",
      "Processing REQ-06: Client handling of Must Support data elements\n",
      "\n",
      "================================================================================\n",
      "RAG RETRIEVAL FOR REQ-06\n",
      "================================================================================\n",
      "Query: Client handling of Must Support data elements \"Application actors SHALL be capable of processing resource instances containing the Must Support data elements without generating an error or causing the application to fail.\" Application Actor FHIR SHALL\n",
      "Searching for 5 most relevant capability chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2653c1786ca945e3b2a22df8b9f3db0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 5 matching chunks:\n",
      "\n",
      "  Match 1 (distance: 0.924159049987793):\n",
      "  Length: 802 chars\n",
      "  Preview: FHIR Major Section: ## Plan\\-Net CapabilityStatement\n",
      "\n",
      "* Implementation Guide Version: 1\\.0\\.0\n",
      "* FHIR...\n",
      "  ...local use cases and other contextual requirements.\n",
      "\n",
      "  Match 2 (distance: 0.9948651790618896):\n",
      "  Length: 2854 chars\n",
      "  Preview: FHIR Resource Detail: #### PractitionerRole\n",
      "\n",
      "Conformance Expectation: **SHALL**\n",
      "\n",
      "Supported Profiles:...\n",
      "  ...actitionerRole?_lastUpdated=[_lastUpdated]` |\n",
      "\n",
      "---\n",
      "\n",
      "  Match 3 (distance: 0.9952019453048706):\n",
      "  Length: 996 chars\n",
      "  Preview: FHIR Major Section: ## CapabilityStatement: Plan\\-Net CapabilityStatement\n",
      "\n",
      "| *Official URL*: http://...\n",
      "  ...openapi.json) \\| [Download](plan-net.openapi.json)\n",
      "\n",
      "  Match 4 (distance: 1.0001834630966187):\n",
      "  Length: 3225 chars\n",
      "  Preview: FHIR Resource Detail: #### Organization\n",
      "\n",
      "Conformance Expectation: **SHALL**\n",
      "\n",
      "Supported Profiles:\n",
      "\n",
      " [...\n",
      "  ...Organization?coverage-area=[coverage-area]` |\n",
      "\n",
      "---\n",
      "\n",
      "  Match 5 (distance: 1.0239274501800537):\n",
      "  Length: 2302 chars\n",
      "  Preview: FHIR Resource Detail: #### InsurancePlan\n",
      "\n",
      "Conformance Expectation: **SHALL**\n",
      "\n",
      "Supported Profiles:\n",
      "\n",
      " ...\n",
      "  ... [base]/InsurancePlan?type=[system]|[code]` |\n",
      "\n",
      "---\n",
      "================================================================================\n",
      "\n",
      "Sending request to GEMINI API...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 12:28:04,851 - llm_utils - INFO - Processing requirement for group 'Plan-Net Endpoint': REQ-02\n",
      "2025-07-09 12:28:04,852 - llm_utils - INFO - Generating test specification for REQ-02 using gemini...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed test specification for REQ-06\n",
      "\n",
      "Processing Group: Plan-Net Endpoint (3 requirements)\n",
      "\n",
      "Processing REQ-02: No PII sending by clients\n",
      "\n",
      "================================================================================\n",
      "RAG RETRIEVAL FOR REQ-02\n",
      "================================================================================\n",
      "Query: No PII sending by clients \"A directory mobile application SHALL NOT send consumer identifiable information when querying a Plan-Net service.\" Application Actor FHIR SHALL NOT\n",
      "Searching for 5 most relevant capability chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9662e1e73df245e8a1557885be6a3854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 5 matching chunks:\n",
      "\n",
      "  Match 1 (distance: 0.9052037000656128):\n",
      "  Length: 802 chars\n",
      "  Preview: FHIR Major Section: ## Plan\\-Net CapabilityStatement\n",
      "\n",
      "* Implementation Guide Version: 1\\.0\\.0\n",
      "* FHIR...\n",
      "  ...local use cases and other contextual requirements.\n",
      "\n",
      "  Match 2 (distance: 0.9250739812850952):\n",
      "  Length: 996 chars\n",
      "  Preview: FHIR Major Section: ## CapabilityStatement: Plan\\-Net CapabilityStatement\n",
      "\n",
      "| *Official URL*: http://...\n",
      "  ...openapi.json) \\| [Download](plan-net.openapi.json)\n",
      "\n",
      "  Match 3 (distance: 0.9963822364807129):\n",
      "  Length: 1169 chars\n",
      "  Preview: FHIR Resource/Component: ### FHIR RESTful Capabilities\n",
      "\n",
      "The Plan\\-Net Server **SHALL**:\n",
      "\n",
      "1. Support ...\n",
      "  ...eturning an `HTTP 401` unauthorized response code.\n",
      "\n",
      "  Match 4 (distance: 1.0774399042129517):\n",
      "  Length: 2854 chars\n",
      "  Preview: FHIR Resource Detail: #### PractitionerRole\n",
      "\n",
      "Conformance Expectation: **SHALL**\n",
      "\n",
      "Supported Profiles:...\n",
      "  ...actitionerRole?_lastUpdated=[_lastUpdated]` |\n",
      "\n",
      "---\n",
      "\n",
      "  Match 5 (distance: 1.1062846183776855):\n",
      "  Length: 3225 chars\n",
      "  Preview: FHIR Resource Detail: #### Organization\n",
      "\n",
      "Conformance Expectation: **SHALL**\n",
      "\n",
      "Supported Profiles:\n",
      "\n",
      " [...\n",
      "  ...Organization?coverage-area=[coverage-area]` |\n",
      "\n",
      "---\n",
      "================================================================================\n",
      "\n",
      "Sending request to GEMINI API...\n",
      "Completed test specification for REQ-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 12:28:43,291 - llm_utils - INFO - Processing requirement for group 'Plan-Net Endpoint': REQ-03\n",
      "2025-07-09 12:28:43,293 - llm_utils - INFO - Generating test specification for REQ-03 using gemini...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing REQ-03: Population of Must Support data elements\n",
      "\n",
      "================================================================================\n",
      "RAG RETRIEVAL FOR REQ-03\n",
      "================================================================================\n",
      "Query: Population of Must Support data elements \"Health Plan API actors SHALL be capable of populating all Must Support data elements as part of the query results.\" Health Plan API FHIR SHALL\n",
      "Searching for 5 most relevant capability chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f427fa374aa473aaddf7202f197394a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 5 matching chunks:\n",
      "\n",
      "  Match 1 (distance: 0.7593825459480286):\n",
      "  Length: 3288 chars\n",
      "  Preview: FHIR Resource/Component: ### RESTful Capabilities by Resource/Profile:\n",
      "\n",
      "**Summary of Search Criteria...\n",
      "  ...nerRole:network, PractitionerRole:endpoint |  |  |\n",
      "\n",
      "  Match 2 (distance: 0.7934293150901794):\n",
      "  Length: 3036 chars\n",
      "  Preview: FHIR Resource Detail: #### HealthcareService\n",
      "\n",
      "Conformance Expectation: **SHALL**\n",
      "\n",
      "Supported Profiles...\n",
      "  ...lthcareService?_lastUpdated=[_lastUpdated]` |\n",
      "\n",
      "---\n",
      "\n",
      "  Match 3 (distance: 0.9118645787239075):\n",
      "  Length: 2302 chars\n",
      "  Preview: FHIR Resource Detail: #### InsurancePlan\n",
      "\n",
      "Conformance Expectation: **SHALL**\n",
      "\n",
      "Supported Profiles:\n",
      "\n",
      " ...\n",
      "  ... [base]/InsurancePlan?type=[system]|[code]` |\n",
      "\n",
      "---\n",
      "\n",
      "  Match 4 (distance: 0.923588752746582):\n",
      "  Length: 3225 chars\n",
      "  Preview: FHIR Resource Detail: #### Organization\n",
      "\n",
      "Conformance Expectation: **SHALL**\n",
      "\n",
      "Supported Profiles:\n",
      "\n",
      " [...\n",
      "  ...Organization?coverage-area=[coverage-area]` |\n",
      "\n",
      "---\n",
      "\n",
      "  Match 5 (distance: 0.9848544597625732):\n",
      "  Length: 996 chars\n",
      "  Preview: FHIR Major Section: ## CapabilityStatement: Plan\\-Net CapabilityStatement\n",
      "\n",
      "| *Official URL*: http://...\n",
      "  ...openapi.json) \\| [Download](plan-net.openapi.json)\n",
      "================================================================================\n",
      "\n",
      "Sending request to GEMINI API...\n",
      "Completed test specification for REQ-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 12:29:36,644 - llm_utils - INFO - Processing requirement for group 'Plan-Net Endpoint': REQ-10\n",
      "2025-07-09 12:29:36,648 - llm_utils - INFO - Generating test specification for REQ-10 using gemini...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing REQ-10: JSON format support\n",
      "\n",
      "================================================================================\n",
      "RAG RETRIEVAL FOR REQ-10\n",
      "================================================================================\n",
      "Query: JSON format support \"Support json source formats for all Plan-Net interactions.\" Health Plan API FHIR SHALL\n",
      "Searching for 5 most relevant capability chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5df00bdcd6094b6bb170118771ddb68a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 5 matching chunks:\n",
      "\n",
      "  Match 1 (distance: 0.7856061458587646):\n",
      "  Length: 3288 chars\n",
      "  Preview: FHIR Resource/Component: ### RESTful Capabilities by Resource/Profile:\n",
      "\n",
      "**Summary of Search Criteria...\n",
      "  ...nerRole:network, PractitionerRole:endpoint |  |  |\n",
      "\n",
      "  Match 2 (distance: 0.7965418696403503):\n",
      "  Length: 3036 chars\n",
      "  Preview: FHIR Resource Detail: #### HealthcareService\n",
      "\n",
      "Conformance Expectation: **SHALL**\n",
      "\n",
      "Supported Profiles...\n",
      "  ...lthcareService?_lastUpdated=[_lastUpdated]` |\n",
      "\n",
      "---\n",
      "\n",
      "  Match 3 (distance: 0.8781458139419556):\n",
      "  Length: 1169 chars\n",
      "  Preview: FHIR Resource/Component: ### FHIR RESTful Capabilities\n",
      "\n",
      "The Plan\\-Net Server **SHALL**:\n",
      "\n",
      "1. Support ...\n",
      "  ...eturning an `HTTP 401` unauthorized response code.\n",
      "\n",
      "  Match 4 (distance: 0.8851763010025024):\n",
      "  Length: 3225 chars\n",
      "  Preview: FHIR Resource Detail: #### Organization\n",
      "\n",
      "Conformance Expectation: **SHALL**\n",
      "\n",
      "Supported Profiles:\n",
      "\n",
      " [...\n",
      "  ...Organization?coverage-area=[coverage-area]` |\n",
      "\n",
      "---\n",
      "\n",
      "  Match 5 (distance: 0.9248039722442627):\n",
      "  Length: 996 chars\n",
      "  Preview: FHIR Major Section: ## CapabilityStatement: Plan\\-Net CapabilityStatement\n",
      "\n",
      "| *Official URL*: http://...\n",
      "  ...openapi.json) \\| [Download](plan-net.openapi.json)\n",
      "================================================================================\n",
      "\n",
      "Sending request to GEMINI API...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 12:30:10,650 - llm_utils - INFO - Consolidated test plan saved to checkpoints/testplan_generation/gemini_test_plan_20250709_122419.md\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed test specification for REQ-10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'requirements_count': 5,\n",
       " 'group_count': 3,\n",
       " 'test_plan_path': 'checkpoints/testplan_generation/gemini_test_plan_20250709_122419.md'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "req_to_testplan_rag.generate_consolidated_test_plan(\n",
    "    llm_clients, \n",
    "    'gemini', \n",
    "    llm_clients.logger, \n",
    "    \"/Users/ceadams/Documents/onclaive/onclaive/reqs_extraction/revised_reqs_output/small-plan-net-requirements-v4.md\", \n",
    "    \"../full-ig/markdown7_cleaned/CapabilityStatement_plan_net.md\", \n",
    "    \"Plan-Net IG\",\n",
    "    output_dir='checkpoints/testplan_generation',\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1c5f32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chunk analysis saved to: capability_chunks_analysis_20250702_135655.md\n",
      "📊 Total chunks analyzed: 13\n",
      "\n",
      "📋 QUICK SUMMARY:\n",
      "   Total chunks: 13\n",
      "   Resource sections: 0\n",
      "   Table sections: 0\n",
      "   General sections: 0\n",
      "   Other: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-02 13:57:00,559 - backoff - ERROR - Giving up send_request(...) after 4 tries (requests.exceptions.SSLError: HTTPSConnectionPool(host='us.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)'))))\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def inspect_capability_chunks(output_file=None):\n",
    "    \"\"\"\n",
    "    Inspect all chunks stored in the ChromaDB collection and save to markdown file\n",
    "    \"\"\"\n",
    "    # Connect to ChromaDB\n",
    "    chroma_client = chromadb.Client()\n",
    "    sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "        model_name=\"all-mpnet-base-v2\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Get the existing collection\n",
    "        collection = chroma_client.get_collection('capability_statements', embedding_function=sentence_transformer_ef)\n",
    "        \n",
    "        # Get all documents\n",
    "        all_docs = collection.get()\n",
    "        \n",
    "        # Create output file name if not provided\n",
    "        if output_file is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_file = f\"capability_chunks_analysis_{timestamp}.md\"\n",
    "        \n",
    "        # Prepare markdown content\n",
    "        markdown_content = []\n",
    "        \n",
    "        # Header\n",
    "        markdown_content.append(\"# Capability Statement Chunking Analysis\")\n",
    "        markdown_content.append(f\"*Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\\n\")\n",
    "        \n",
    "        # Summary statistics\n",
    "        chunk_lengths = [len(doc) for doc in all_docs['documents']]\n",
    "        markdown_content.append(\"## 📊 Summary Statistics\")\n",
    "        markdown_content.append(f\"- **Total chunks**: {len(all_docs['documents'])}\")\n",
    "        markdown_content.append(f\"- **Average chunk length**: {sum(chunk_lengths) / len(chunk_lengths):.1f} characters\")\n",
    "        markdown_content.append(f\"- **Shortest chunk**: {min(chunk_lengths)} characters\")\n",
    "        markdown_content.append(f\"- **Longest chunk**: {max(chunk_lengths)} characters\\n\")\n",
    "        \n",
    "        # Chunk type analysis\n",
    "        chunk_types = {\n",
    "            'Resource sections': 0,\n",
    "            'Table sections': 0,\n",
    "            'General sections': 0,\n",
    "            'Other': 0\n",
    "        }\n",
    "        \n",
    "        for doc in all_docs['documents']:\n",
    "            if 'FHIR' in doc and 'Resource:' in doc:\n",
    "                chunk_types['Resource sections'] += 1\n",
    "            elif 'FHIR Capability Table:' in doc:\n",
    "                chunk_types['Table sections'] += 1\n",
    "            elif 'FHIR Capability Statement:' in doc:\n",
    "                chunk_types['General sections'] += 1\n",
    "            else:\n",
    "                chunk_types['Other'] += 1\n",
    "        \n",
    "        markdown_content.append(\"## 🔍 Chunk Type Analysis\")\n",
    "        for chunk_type, count in chunk_types.items():\n",
    "            markdown_content.append(f\"- **{chunk_type}**: {count} chunks\")\n",
    "        markdown_content.append(\"\")\n",
    "        \n",
    "        # Table of contents\n",
    "        markdown_content.append(\"## 📋 Table of Contents\")\n",
    "        for i in range(len(all_docs['documents'])):\n",
    "            doc = all_docs['documents'][i]\n",
    "            # Create a short preview for TOC\n",
    "            preview = doc[:50].replace('\\n', ' ').strip()\n",
    "            if len(doc) > 50:\n",
    "                preview += \"...\"\n",
    "            markdown_content.append(f\"- [Chunk {i+1}](#chunk-{i+1}) ({len(doc)} chars): {preview}\")\n",
    "        markdown_content.append(\"\")\n",
    "        \n",
    "        # Detailed chunks\n",
    "        markdown_content.append(\"## 📄 Detailed Chunk Analysis\")\n",
    "        \n",
    "        for i, doc in enumerate(all_docs['documents']):\n",
    "            # Chunk header\n",
    "            markdown_content.append(f\"### Chunk {i+1}\")\n",
    "            markdown_content.append(f\"**Length**: {len(doc)} characters  \")\n",
    "            markdown_content.append(f\"**ID**: {all_docs['ids'][i]}  \")\n",
    "            \n",
    "            # Determine chunk type\n",
    "            chunk_type = \"Other\"\n",
    "            if 'FHIR' in doc and 'Resource:' in doc:\n",
    "                chunk_type = \"Resource Section\"\n",
    "            elif 'FHIR Capability Table:' in doc:\n",
    "                chunk_type = \"Table Section\"\n",
    "            elif 'FHIR Capability Statement:' in doc:\n",
    "                chunk_type = \"General Section\"\n",
    "            \n",
    "            markdown_content.append(f\"**Type**: {chunk_type}\\n\")\n",
    "            \n",
    "            # Content in code block for better formatting\n",
    "            markdown_content.append(\"**Content:**\")\n",
    "            markdown_content.append(\"```\")\n",
    "            markdown_content.append(doc)\n",
    "            markdown_content.append(\"```\\n\")\n",
    "            \n",
    "            markdown_content.append(\"---\\n\")\n",
    "        \n",
    "        # Write to file\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write('\\n'.join(markdown_content))\n",
    "        \n",
    "        print(f\"✅ Chunk analysis saved to: {output_file}\")\n",
    "        print(f\"📊 Total chunks analyzed: {len(all_docs['documents'])}\")\n",
    "        \n",
    "        # Also print summary to console\n",
    "        print(f\"\\n📋 QUICK SUMMARY:\")\n",
    "        print(f\"   Total chunks: {len(all_docs['documents'])}\")\n",
    "        for chunk_type, count in chunk_types.items():\n",
    "            print(f\"   {chunk_type}: {count}\")\n",
    "            \n",
    "        return all_docs, output_file\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error inspecting collection: {e}\")\n",
    "        print(\"Make sure you've run the script first to create the collection!\")\n",
    "        return None, None\n",
    "\n",
    "def quick_chunk_preview(output_file=None, num_chunks=5):\n",
    "    \"\"\"Create a shorter markdown file with just preview of first few chunks\"\"\"\n",
    "    chroma_client = chromadb.Client()\n",
    "    sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "        model_name=\"all-mpnet-base-v2\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        collection = chroma_client.get_collection('capability_statements', embedding_function=sentence_transformer_ef)\n",
    "        all_docs = collection.get()\n",
    "        \n",
    "        if output_file is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_file = f\"capability_chunks_preview_{timestamp}.md\"\n",
    "        \n",
    "        markdown_content = []\n",
    "        markdown_content.append(\"# Capability Statement Chunks Preview\")\n",
    "        markdown_content.append(f\"*Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\\n\")\n",
    "        markdown_content.append(f\"Showing first {num_chunks} chunks out of {len(all_docs['documents'])} total\\n\")\n",
    "        \n",
    "        for i in range(min(num_chunks, len(all_docs['documents']))):\n",
    "            doc = all_docs['documents'][i]\n",
    "            markdown_content.append(f\"## Chunk {i+1}\")\n",
    "            markdown_content.append(f\"**Length**: {len(doc)} characters\\n\")\n",
    "            markdown_content.append(\"```\")\n",
    "            markdown_content.append(doc)\n",
    "            markdown_content.append(\"```\\n\")\n",
    "        \n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write('\\n'.join(markdown_content))\n",
    "        \n",
    "        print(f\"✅ Chunk preview saved to: {output_file}\")\n",
    "        return output_file\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Run the full analysis and save to markdown\n",
    "chunks_data, analysis_file = inspect_capability_chunks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d080ace6",
   "metadata": {},
   "source": [
    "## Test Kit Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ef90585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-19 15:10:47,505 - plan_to_tests - INFO - Starting Inferno test generation with claude for PlanNet\n",
      "2025-06-19 15:10:47,516 - plan_to_tests - INFO - Parsed test plan into 11 sections\n",
      "2025-06-19 15:10:47,516 - plan_to_tests - INFO - Found 11 total requirements\n",
      "2025-06-19 15:10:47,518 - plan_to_tests - INFO - Loaded Inferno DSL guidance\n",
      "2025-06-19 15:10:47,518 - plan_to_tests - INFO - Processing section: Application-Level Requirements with 1 requirements\n",
      "2025-06-19 15:10:47,518 - plan_to_tests - INFO - Generating tests for section: Application-Level Requirements\n",
      "2025-06-19 15:10:47,519 - plan_to_tests - INFO - Generating test for requirement: REQ-08\n",
      "2025-06-19 15:10:47,520 - plan_to_tests - INFO - Requirement REQ-08: Sending 989 tokens to claude API (limit: 16000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11 potential requirements\n",
      "Processing requirement: REQ-08\n",
      "Added requirement REQ-08 to section Application-Level Requirements\n",
      "Processing requirement: REQ-01\n",
      "Added requirement REQ-01 to section Authentication\n",
      "Processing requirement: REQ-09\n",
      "Added requirement REQ-09 to section Base Requirements\n",
      "Processing requirement: REQ-07\n",
      "Added requirement REQ-07 to section CORE Conformance\n",
      "Processing requirement: REQ-06\n",
      "Added requirement REQ-06 to section Cross-Resource\n",
      "Processing requirement: REQ-04\n",
      "Added requirement REQ-04 to section General Requirements\n",
      "Processing requirement: REQ-05\n",
      "Added requirement REQ-05 to section Global\n",
      "Processing requirement: REQ-11\n",
      "Added requirement REQ-11 to section OrganizationAffiliation\n",
      "Processing requirement: REQ-02\n",
      "Added requirement REQ-02 to section Plan-Net API Security\n",
      "Processing requirement: REQ-10\n",
      "Added requirement REQ-10 to section PractitionerRole\n",
      "Processing requirement: REQ-03\n",
      "Added requirement REQ-03 to section Security\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-19 15:10:58,370 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-06-19 15:10:58,371 - plan_to_tests - INFO - Successfully generated test for requirement: REQ-08\n",
      "2025-06-19 15:10:58,372 - plan_to_tests - INFO - Validating test for requirement: REQ-08\n",
      "2025-06-19 15:10:58,372 - plan_to_tests - INFO - Validation for test: Sending 1528 tokens to claude API\n",
      "2025-06-19 15:11:07,548 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-06-19 15:11:07,552 - plan_to_tests - INFO - Successfully validated test for requirement: REQ-08\n",
      "2025-06-19 15:11:10,556 - plan_to_tests - INFO - Processing section: Authentication with 1 requirements\n",
      "2025-06-19 15:11:10,558 - plan_to_tests - INFO - Generating tests for section: Authentication\n",
      "2025-06-19 15:11:10,562 - plan_to_tests - INFO - Generating test for requirement: REQ-01\n",
      "2025-06-19 15:11:10,565 - plan_to_tests - INFO - Requirement REQ-01: Sending 983 tokens to claude API (limit: 16000)\n",
      "2025-06-19 15:11:23,339 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-06-19 15:11:23,340 - plan_to_tests - INFO - Successfully generated test for requirement: REQ-01\n",
      "2025-06-19 15:11:23,341 - plan_to_tests - INFO - Validating test for requirement: REQ-01\n",
      "2025-06-19 15:11:23,341 - plan_to_tests - INFO - Validation for test: Sending 1630 tokens to claude API\n",
      "2025-06-19 15:11:34,156 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-06-19 15:11:34,158 - plan_to_tests - INFO - Successfully validated test for requirement: REQ-01\n",
      "2025-06-19 15:11:37,164 - plan_to_tests - INFO - Processing section: Base Requirements with 1 requirements\n",
      "2025-06-19 15:11:37,165 - plan_to_tests - INFO - Generating tests for section: Base Requirements\n",
      "2025-06-19 15:11:37,165 - plan_to_tests - INFO - Generating test for requirement: REQ-09\n",
      "2025-06-19 15:11:37,167 - plan_to_tests - INFO - Requirement REQ-09: Sending 993 tokens to claude API (limit: 16000)\n",
      "2025-06-19 15:11:51,011 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-06-19 15:11:51,012 - plan_to_tests - INFO - Successfully generated test for requirement: REQ-09\n",
      "2025-06-19 15:11:51,012 - plan_to_tests - INFO - Validating test for requirement: REQ-09\n",
      "2025-06-19 15:11:51,012 - plan_to_tests - INFO - Validation for test: Sending 1545 tokens to claude API\n",
      "2025-06-19 15:12:02,103 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-06-19 15:12:02,106 - plan_to_tests - INFO - Successfully validated test for requirement: REQ-09\n",
      "2025-06-19 15:12:05,112 - plan_to_tests - INFO - Processing section: CORE Conformance with 1 requirements\n",
      "2025-06-19 15:12:05,113 - plan_to_tests - INFO - Generating tests for section: CORE Conformance\n",
      "2025-06-19 15:12:05,114 - plan_to_tests - INFO - Generating test for requirement: REQ-07\n",
      "2025-06-19 15:12:05,116 - plan_to_tests - INFO - Requirement REQ-07: Sending 995 tokens to claude API (limit: 16000)\n",
      "2025-06-19 15:12:19,351 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-06-19 15:12:19,355 - plan_to_tests - INFO - Successfully generated test for requirement: REQ-07\n",
      "2025-06-19 15:12:19,356 - plan_to_tests - INFO - Validating test for requirement: REQ-07\n",
      "2025-06-19 15:12:19,356 - plan_to_tests - INFO - Validation for test: Sending 1819 tokens to claude API\n",
      "2025-06-19 15:12:30,963 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-06-19 15:12:30,968 - plan_to_tests - INFO - Successfully validated test for requirement: REQ-07\n",
      "2025-06-19 15:12:33,974 - plan_to_tests - INFO - Processing section: Cross-Resource with 1 requirements\n",
      "2025-06-19 15:12:33,975 - plan_to_tests - INFO - Generating tests for section: Cross-Resource\n",
      "2025-06-19 15:12:33,975 - plan_to_tests - INFO - Generating test for requirement: REQ-06\n",
      "2025-06-19 15:12:33,979 - plan_to_tests - INFO - Requirement REQ-06: Sending 1009 tokens to claude API (limit: 16000)\n",
      "2025-06-19 15:12:49,303 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-06-19 15:12:49,305 - plan_to_tests - INFO - Successfully generated test for requirement: REQ-06\n",
      "2025-06-19 15:12:49,305 - plan_to_tests - INFO - Validating test for requirement: REQ-06\n",
      "2025-06-19 15:12:49,305 - plan_to_tests - INFO - Validation for test: Sending 1728 tokens to claude API\n",
      "2025-06-19 15:13:03,122 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-06-19 15:13:03,125 - plan_to_tests - INFO - Successfully validated test for requirement: REQ-06\n",
      "2025-06-19 15:13:06,132 - plan_to_tests - INFO - Processing section: General Requirements with 1 requirements\n",
      "2025-06-19 15:13:06,133 - plan_to_tests - INFO - Generating tests for section: General Requirements\n",
      "2025-06-19 15:13:06,133 - plan_to_tests - INFO - Generating test for requirement: REQ-04\n",
      "2025-06-19 15:13:06,135 - plan_to_tests - INFO - Requirement REQ-04: Sending 983 tokens to claude API (limit: 16000)\n",
      "2025-06-19 15:13:18,851 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-06-19 15:13:18,853 - plan_to_tests - INFO - Successfully generated test for requirement: REQ-04\n",
      "2025-06-19 15:13:18,853 - plan_to_tests - INFO - Validating test for requirement: REQ-04\n",
      "2025-06-19 15:13:18,854 - plan_to_tests - INFO - Validation for test: Sending 1558 tokens to claude API\n",
      "2025-06-19 15:13:29,254 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-06-19 15:13:29,258 - plan_to_tests - INFO - Successfully validated test for requirement: REQ-04\n",
      "2025-06-19 15:13:32,263 - plan_to_tests - INFO - Processing section: Global with 1 requirements\n",
      "2025-06-19 15:13:32,264 - plan_to_tests - INFO - Generating tests for section: Global\n",
      "2025-06-19 15:13:32,267 - plan_to_tests - INFO - Generating test for requirement: REQ-05\n",
      "2025-06-19 15:13:32,270 - plan_to_tests - INFO - Requirement REQ-05: Sending 1002 tokens to claude API (limit: 16000)\n",
      "2025-06-19 15:13:44,106 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-06-19 15:13:44,108 - plan_to_tests - INFO - Successfully generated test for requirement: REQ-05\n",
      "2025-06-19 15:13:44,108 - plan_to_tests - INFO - Validating test for requirement: REQ-05\n",
      "2025-06-19 15:13:44,108 - plan_to_tests - INFO - Validation for test: Sending 1531 tokens to claude API\n",
      "2025-06-19 15:13:54,353 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-06-19 15:13:54,357 - plan_to_tests - INFO - Successfully validated test for requirement: REQ-05\n",
      "2025-06-19 15:13:57,358 - plan_to_tests - INFO - Processing section: OrganizationAffiliation with 1 requirements\n",
      "2025-06-19 15:13:57,359 - plan_to_tests - INFO - Generating tests for section: OrganizationAffiliation\n",
      "2025-06-19 15:13:57,359 - plan_to_tests - INFO - Generating test for requirement: REQ-11\n",
      "2025-06-19 15:13:57,360 - plan_to_tests - INFO - Requirement REQ-11: Sending 996 tokens to claude API (limit: 16000)\n",
      "2025-06-19 15:14:10,157 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-06-19 15:14:10,159 - plan_to_tests - INFO - Successfully generated test for requirement: REQ-11\n",
      "2025-06-19 15:14:10,159 - plan_to_tests - INFO - Validating test for requirement: REQ-11\n",
      "2025-06-19 15:14:10,160 - plan_to_tests - INFO - Validation for test: Sending 1534 tokens to claude API\n",
      "2025-06-19 15:14:19,458 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-06-19 15:14:19,459 - plan_to_tests - INFO - Successfully validated test for requirement: REQ-11\n",
      "2025-06-19 15:14:22,463 - plan_to_tests - INFO - Processing section: Plan-Net API Security with 1 requirements\n",
      "2025-06-19 15:14:22,463 - plan_to_tests - INFO - Generating tests for section: Plan-Net API Security\n",
      "2025-06-19 15:14:22,463 - plan_to_tests - INFO - Generating test for requirement: REQ-02\n",
      "2025-06-19 15:14:22,464 - plan_to_tests - INFO - Requirement REQ-02: Sending 995 tokens to claude API (limit: 16000)\n",
      "2025-06-19 15:14:34,016 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-06-19 15:14:34,020 - plan_to_tests - INFO - Successfully generated test for requirement: REQ-02\n",
      "2025-06-19 15:14:34,021 - plan_to_tests - INFO - Validating test for requirement: REQ-02\n",
      "2025-06-19 15:14:34,021 - plan_to_tests - INFO - Validation for test: Sending 1475 tokens to claude API\n",
      "2025-06-19 15:14:43,112 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-06-19 15:14:43,114 - plan_to_tests - INFO - Successfully validated test for requirement: REQ-02\n",
      "2025-06-19 15:14:46,120 - plan_to_tests - INFO - Processing section: PractitionerRole with 1 requirements\n",
      "2025-06-19 15:14:46,121 - plan_to_tests - INFO - Generating tests for section: PractitionerRole\n",
      "2025-06-19 15:14:46,122 - plan_to_tests - INFO - Generating test for requirement: REQ-10\n",
      "2025-06-19 15:14:46,125 - plan_to_tests - INFO - Requirement REQ-10: Sending 994 tokens to claude API (limit: 16000)\n",
      "2025-06-19 15:14:59,826 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-06-19 15:14:59,834 - plan_to_tests - INFO - Successfully generated test for requirement: REQ-10\n",
      "2025-06-19 15:14:59,835 - plan_to_tests - INFO - Validating test for requirement: REQ-10\n",
      "2025-06-19 15:14:59,836 - plan_to_tests - INFO - Validation for test: Sending 1615 tokens to claude API\n",
      "2025-06-19 15:15:10,306 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-06-19 15:15:10,307 - plan_to_tests - INFO - Successfully validated test for requirement: REQ-10\n",
      "2025-06-19 15:15:13,315 - plan_to_tests - INFO - Processing section: Security with 1 requirements\n",
      "2025-06-19 15:15:13,319 - plan_to_tests - INFO - Generating tests for section: Security\n",
      "2025-06-19 15:15:13,319 - plan_to_tests - INFO - Generating test for requirement: REQ-03\n",
      "2025-06-19 15:15:13,321 - plan_to_tests - INFO - Requirement REQ-03: Sending 990 tokens to claude API (limit: 16000)\n",
      "2025-06-19 15:15:23,432 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-06-19 15:15:23,434 - plan_to_tests - INFO - Successfully generated test for requirement: REQ-03\n",
      "2025-06-19 15:15:23,435 - plan_to_tests - INFO - Validating test for requirement: REQ-03\n",
      "2025-06-19 15:15:23,435 - plan_to_tests - INFO - Validation for test: Sending 1401 tokens to claude API\n",
      "2025-06-19 15:15:32,493 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-06-19 15:15:32,494 - plan_to_tests - INFO - Successfully validated test for requirement: REQ-03\n",
      "2025-06-19 15:15:35,500 - plan_to_tests - INFO - Generated tests for 11 requirements\n",
      "2025-06-19 15:15:35,502 - plan_to_tests - INFO - Wrote test for REQ-08 to checkpoints/testkit_generation/plannet/application_actor/application_level_requirements/req_08_test.rb\n",
      "2025-06-19 15:15:35,502 - plan_to_tests - INFO - Wrote test for REQ-09 to checkpoints/testkit_generation/plannet/application_actor/base_requirements/req_09_test.rb\n",
      "2025-06-19 15:15:35,503 - plan_to_tests - INFO - Wrote test for REQ-07 to checkpoints/testkit_generation/plannet/application_actor/core_conformance/req_07_test.rb\n",
      "2025-06-19 15:15:35,504 - plan_to_tests - INFO - Wrote test for REQ-03 to checkpoints/testkit_generation/plannet/application_actor/security/req_03_test.rb\n",
      "2025-06-19 15:15:35,505 - plan_to_tests - INFO - Wrote test for REQ-01 to checkpoints/testkit_generation/plannet/health_plan_api/authentication/req_01_test.rb\n",
      "2025-06-19 15:15:35,506 - plan_to_tests - INFO - Wrote test for REQ-06 to checkpoints/testkit_generation/plannet/health_plan_api/cross_resource/req_06_test.rb\n",
      "2025-06-19 15:15:35,507 - plan_to_tests - INFO - Wrote test for REQ-04 to checkpoints/testkit_generation/plannet/health_plan_api/general_requirements/req_04_test.rb\n",
      "2025-06-19 15:15:35,508 - plan_to_tests - INFO - Wrote test for REQ-05 to checkpoints/testkit_generation/plannet/health_plan_api/global/req_05_test.rb\n",
      "2025-06-19 15:15:35,509 - plan_to_tests - INFO - Wrote test for REQ-11 to checkpoints/testkit_generation/plannet/health_plan_api/organizationaffiliation/req_11_test.rb\n",
      "2025-06-19 15:15:35,509 - plan_to_tests - INFO - Wrote test for REQ-02 to checkpoints/testkit_generation/plannet/health_plan_api/plan_net_api_security/req_02_test.rb\n",
      "2025-06-19 15:15:35,510 - plan_to_tests - INFO - Wrote test for REQ-10 to checkpoints/testkit_generation/plannet/health_plan_api/practitionerrole/req_10_test.rb\n",
      "2025-06-19 15:15:35,510 - plan_to_tests - INFO - Collecting test data for module file generation\n",
      "2025-06-19 15:15:35,517 - plan_to_tests - INFO - Created structure representation of test files\n",
      "2025-06-19 15:15:35,517 - plan_to_tests - INFO - Generating module file with LLM\n",
      "2025-06-19 15:15:45,940 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-06-19 15:15:45,946 - plan_to_tests - INFO - Wrote module file to checkpoints/testkit_generation/plannet.rb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_sections': 11,\n",
       " 'total_requirements': 11,\n",
       " 'generated_tests': 11,\n",
       " 'module_dir': 'checkpoints/testkit_generation/plannet',\n",
       " 'module_file': 'checkpoints/testkit_generation/plannet.rb'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plan_to_tests\n",
    "importlib.reload(plan_to_tests)\n",
    "\n",
    "plan_to_tests.generate_inferno_test_kit(\n",
    "    llm_clients,\n",
    "    'claude',\n",
    "    '/Users/ceadams/Documents/onclaive/onclaive/test_kit_dev/test_plan_output/example_claude_test_plan_20250416_143409.md',\n",
    "    #'../test_kit_dev/inferno-guidance.md',\n",
    "    output_dir='checkpoints/testkit_generation',\n",
    "    expected_actors=[\"Health Plan API Actor\", \"Application Actor\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf7dc24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
