{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Results Analysis\n",
    "\n",
    "This notebook is designed to aid in the analysis of the results from the RAG experiments. The current results are stored in a large .JSON file, and this notebook aims to load that data, parse out the relevant information, and export it in a format that can be further analyzed.\n",
    "\n",
    "The notebook includes functions to flatten the processed requirements list into individual rows, each requirement combined with the parent file information. It also processes the JSON file and converts it to a DataFrame, allowing for easier data manipulation and analysis.\n",
    "\n",
    "The notebook also categorizes files based on their \"base file type\" (CodeSystem, SearchParameter, etc.) and provides statistics on the number of unique files, the number of files per category, and the average number of requirements per file within each category.\n",
    "\n",
    "Finally, the notebook exports the processed data to a CSV file for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_requirements(requirements: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Flattens the processed requirements list into individual rows.\n",
    "    Each requirement will be combined with the parent file information.\n",
    "    \"\"\"\n",
    "    flattened = []\n",
    "    for req in requirements:\n",
    "        flat_req = {\n",
    "            'requirement': req.get('Requirement*', ''),\n",
    "            'conformance': req.get('Conformance*', ''),\n",
    "            'actor': req.get('Actor*', ''),\n",
    "            'verifiable': req.get('Verifiable?', ''),\n",
    "            'planning_to_test': req.get('Planning To Test?', ''),\n",
    "            'grouping': req.get('Grouping', ''),\n",
    "            'test_plan': req.get('Test Plan', ''),\n",
    "            'simulation_approach': req.get('Simulation Approach', '')\n",
    "        }\n",
    "        flattened.append(flat_req)\n",
    "    return flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json_to_df(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process the JSON file and convert it to a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    # Read the JSON file\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Initialize list to store all rows\n",
    "    all_rows = []\n",
    "    \n",
    "    # Process each entry in the JSON\n",
    "    for entry in data:\n",
    "        # Extract base information\n",
    "        base_info = {\n",
    "            'file_name': entry.get('file_name', ''),\n",
    "            'chunk_index': entry.get('chunk_index', ''),\n",
    "            'total_chunks': entry.get('total_chunks', ''),\n",
    "            'response': entry.get('response', ''),\n",
    "            'llm_response': entry.get('llm_response', '')\n",
    "        }\n",
    "        \n",
    "        # Process requirements if they exist\n",
    "        if 'processed_requirements' in entry and entry['processed_requirements']:\n",
    "            flattened_reqs = flatten_requirements(entry['processed_requirements'])\n",
    "            \n",
    "            # Combine base info with each requirement\n",
    "            for req in flattened_reqs:\n",
    "                combined_row = {**base_info, **req}\n",
    "                all_rows.append(combined_row)\n",
    "        else:\n",
    "            # If no requirements, just add the base info\n",
    "            all_rows.append(base_info)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    \n",
    "    # Reorder columns to put base info first\n",
    "    base_columns = ['file_name', 'chunk_index', 'total_chunks', 'response', 'llm_response']\n",
    "    other_columns = [col for col in df.columns if col not in base_columns]\n",
    "    df = df[base_columns + other_columns]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'rag-lite-plannet-reqs-processed_v0.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_json_to_df(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>chunk_index</th>\n",
       "      <th>total_chunks</th>\n",
       "      <th>response</th>\n",
       "      <th>llm_response</th>\n",
       "      <th>requirement</th>\n",
       "      <th>conformance</th>\n",
       "      <th>actor</th>\n",
       "      <th>verifiable</th>\n",
       "      <th>planning_to_test</th>\n",
       "      <th>grouping</th>\n",
       "      <th>test_plan</th>\n",
       "      <th>simulation_approach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/site/CodeSystem-DeliveryMethodCS.json</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;ANSWER&gt;YES&lt;/ANSWER&gt;</td>\n",
       "      <td>{\\n  \"Requirement*\": \"Server SHALL support the...</td>\n",
       "      <td>Server SHALL support the CodeSystem 'DeliveryM...</td>\n",
       "      <td>SHALL</td>\n",
       "      <td>Server</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Terminology</td>\n",
       "      <td>Verify that the server supports the DeliveryMe...</td>\n",
       "      <td>SIMULATED: Inferno will include this CodeSyste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/site/CodeSystem-DeliveryMethodCS.json</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;ANSWER&gt;YES&lt;/ANSWER&gt;</td>\n",
       "      <td>{\\n  \"Requirement*\": \"Server SHALL support the...</td>\n",
       "      <td>The DeliveryMethodCS CodeSystem SHALL include ...</td>\n",
       "      <td>SHALL</td>\n",
       "      <td>Server</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Terminology</td>\n",
       "      <td>Verify that the server recognizes and accepts ...</td>\n",
       "      <td>SIMULATED: Inferno will include this code in i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/site/CodeSystem-DeliveryMethodCS.json</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;ANSWER&gt;YES&lt;/ANSWER&gt;</td>\n",
       "      <td>{\\n  \"Requirement*\": \"Server SHALL support the...</td>\n",
       "      <td>The DeliveryMethodCS CodeSystem SHALL include ...</td>\n",
       "      <td>SHALL</td>\n",
       "      <td>Server</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Terminology</td>\n",
       "      <td>Verify that the server recognizes and accepts ...</td>\n",
       "      <td>SIMULATED: Inferno will include this code in i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/site/SearchParameter-organizationaffiliation-...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;ANSWER&gt;YES&lt;/ANSWER&gt;</td>\n",
       "      <td>{\\n  \"Requirement*\": \"Servers SHALL support se...</td>\n",
       "      <td>Servers SHALL support searching OrganizationAf...</td>\n",
       "      <td>SHALL</td>\n",
       "      <td>Server</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Search Parameters</td>\n",
       "      <td>1. Retrieve the server's CapabilityStatement\\n...</td>\n",
       "      <td>SIMULATED: Inferno will implement support for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/site/SearchParameter-organizationaffiliation-...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;ANSWER&gt;YES&lt;/ANSWER&gt;</td>\n",
       "      <td>{\\n  \"Requirement*\": \"Servers SHALL support se...</td>\n",
       "      <td>The 'specialty' search parameter for Organizat...</td>\n",
       "      <td>SHALL</td>\n",
       "      <td>Server</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Search Parameters</td>\n",
       "      <td>1. Retrieve the server's CapabilityStatement\\n...</td>\n",
       "      <td>SIMULATED: Inferno will implement this search ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_name  chunk_index  \\\n",
       "0             /site/CodeSystem-DeliveryMethodCS.json            0   \n",
       "1             /site/CodeSystem-DeliveryMethodCS.json            0   \n",
       "2             /site/CodeSystem-DeliveryMethodCS.json            0   \n",
       "3  /site/SearchParameter-organizationaffiliation-...            0   \n",
       "4  /site/SearchParameter-organizationaffiliation-...            0   \n",
       "\n",
       "   total_chunks              response  \\\n",
       "0             1  <ANSWER>YES</ANSWER>   \n",
       "1             1  <ANSWER>YES</ANSWER>   \n",
       "2             1  <ANSWER>YES</ANSWER>   \n",
       "3             1  <ANSWER>YES</ANSWER>   \n",
       "4             1  <ANSWER>YES</ANSWER>   \n",
       "\n",
       "                                        llm_response  \\\n",
       "0  {\\n  \"Requirement*\": \"Server SHALL support the...   \n",
       "1  {\\n  \"Requirement*\": \"Server SHALL support the...   \n",
       "2  {\\n  \"Requirement*\": \"Server SHALL support the...   \n",
       "3  {\\n  \"Requirement*\": \"Servers SHALL support se...   \n",
       "4  {\\n  \"Requirement*\": \"Servers SHALL support se...   \n",
       "\n",
       "                                         requirement conformance   actor  \\\n",
       "0  Server SHALL support the CodeSystem 'DeliveryM...       SHALL  Server   \n",
       "1  The DeliveryMethodCS CodeSystem SHALL include ...       SHALL  Server   \n",
       "2  The DeliveryMethodCS CodeSystem SHALL include ...       SHALL  Server   \n",
       "3  Servers SHALL support searching OrganizationAf...       SHALL  Server   \n",
       "4  The 'specialty' search parameter for Organizat...       SHALL  Server   \n",
       "\n",
       "  verifiable planning_to_test           grouping  \\\n",
       "0        Yes              Yes        Terminology   \n",
       "1        Yes              Yes        Terminology   \n",
       "2        Yes              Yes        Terminology   \n",
       "3        Yes              Yes  Search Parameters   \n",
       "4        Yes              Yes  Search Parameters   \n",
       "\n",
       "                                           test_plan  \\\n",
       "0  Verify that the server supports the DeliveryMe...   \n",
       "1  Verify that the server recognizes and accepts ...   \n",
       "2  Verify that the server recognizes and accepts ...   \n",
       "3  1. Retrieve the server's CapabilityStatement\\n...   \n",
       "4  1. Retrieve the server's CapabilityStatement\\n...   \n",
       "\n",
       "                                 simulation_approach  \n",
       "0  SIMULATED: Inferno will include this CodeSyste...  \n",
       "1  SIMULATED: Inferno will include this code in i...  \n",
       "2  SIMULATED: Inferno will include this code in i...  \n",
       "3  SIMULATED: Inferno will implement support for ...  \n",
       "4  SIMULATED: Inferno will implement this search ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'analysis_results.csv'\n",
    "df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_files = df['file_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique files: 158\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of unique files: {len(unique_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_files(file_paths):\n",
    "    \"\"\"\n",
    "    Categorizes files based on their base type (CodeSystem, SearchParameter, etc.)\n",
    "    \n",
    "    Args:\n",
    "        file_paths: Array-like object containing file paths\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with base types as keys and lists of files as values\n",
    "    \"\"\"\n",
    "    # Create a defaultdict to store categories\n",
    "    categories = defaultdict(list)\n",
    "    \n",
    "    # Regular expression to extract the base type\n",
    "    # Matches content between /site/ and the next hyphen\n",
    "    pattern = r'/site/([^-]+)-'\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        match = re.search(pattern, file_path)\n",
    "        if match:\n",
    "            base_type = match.group(1)\n",
    "            categories[base_type].append(file_path)\n",
    "    \n",
    "    # Convert defaultdict to regular dict and sort the lists\n",
    "    return {k: sorted(v) for k, v in categories.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorized_files = categorize_files(unique_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique files: 158\n",
      "Number of files per category:\n",
      "  CapabilityStatement: 1\n",
      "  CodeSystem: 10\n",
      "  SearchParameter: 47\n",
      "  StructureDefinition: 21\n",
      "  ValueSet: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of unique files: {len(unique_files)}\")\n",
    "print(\"Number of files per category:\")\n",
    "for category, files in sorted(categorized_files.items()):\n",
    "    print(f\"  {category}: {len(files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CapabilityStatement (1 files):\n",
      "  - CapabilityStatement-plan-net.json\n",
      "\n",
      "CodeSystem (10 files):\n",
      "  - CodeSystem-AcceptingPatientsCS.json\n",
      "  - CodeSystem-DeliveryMethodCS.json\n",
      "  - CodeSystem-EndpointConnectionTypeCS.json\n",
      "  - CodeSystem-EndpointPayloadTypeCS.json\n",
      "  - CodeSystem-HealthcareServiceCategoryCS.json\n",
      "  - CodeSystem-InsurancePlanTypeCS.json\n",
      "  - CodeSystem-InsuranceProductTypeCS.json\n",
      "  - CodeSystem-OrgTypeCS.json\n",
      "  - CodeSystem-ProviderRoleCS.json\n",
      "  - CodeSystem-QualificationStatusCS.json\n",
      "\n",
      "SearchParameter (47 files):\n",
      "  - SearchParameter-healthcareservice-coverage-area.json\n",
      "  - SearchParameter-healthcareservice-delivery-method.json\n",
      "  - SearchParameter-healthcareservice-endpoint.json\n",
      "  - SearchParameter-healthcareservice-location.json\n",
      "  - SearchParameter-healthcareservice-name.json\n",
      "  - SearchParameter-healthcareservice-organization.json\n",
      "  - SearchParameter-healthcareservice-service-type.json\n",
      "  - SearchParameter-healthcareservice-specialty.json\n",
      "  - SearchParameter-insuranceplan-administered-by.json\n",
      "  - SearchParameter-insuranceplan-coverage-area.json\n",
      "  - SearchParameter-insuranceplan-identifier.json\n",
      "  - SearchParameter-insuranceplan-name.json\n",
      "  - SearchParameter-insuranceplan-plan-type.json\n",
      "  - SearchParameter-insuranceplan-type.json\n",
      "  - SearchParameter-location-address-postalcode.json\n",
      "  - SearchParameter-location-address-state.json\n",
      "  - SearchParameter-location-address.json\n",
      "  - SearchParameter-location-endpoint.json\n",
      "  - SearchParameter-location-organization.json\n",
      "  - SearchParameter-location-partof.json\n",
      "  - SearchParameter-location-type.json\n",
      "  - SearchParameter-organization-address.json\n",
      "  - SearchParameter-organization-coverage-area.json\n",
      "  - SearchParameter-organization-endpoint.json\n",
      "  - SearchParameter-organization-name.json\n",
      "  - SearchParameter-organization-type.json\n",
      "  - SearchParameter-organizationaffiliation-endpoint.json\n",
      "  - SearchParameter-organizationaffiliation-location.json\n",
      "  - SearchParameter-organizationaffiliation-network.json\n",
      "  - SearchParameter-organizationaffiliation-participating-organization.json\n",
      "  - SearchParameter-organizationaffiliation-period.json\n",
      "  - SearchParameter-organizationaffiliation-primary-organization.json\n",
      "  - SearchParameter-organizationaffiliation-role.json\n",
      "  - SearchParameter-organizationaffiliation-service.json\n",
      "  - SearchParameter-organizationaffiliation-specialty.json\n",
      "  - SearchParameter-practitioner-family-name.json\n",
      "  - SearchParameter-practitioner-given-name.json\n",
      "  - SearchParameter-practitioner-name.json\n",
      "  - SearchParameter-practitionerrole-endpoint.json\n",
      "  - SearchParameter-practitionerrole-location.json\n",
      "  - SearchParameter-practitionerrole-network.json\n",
      "  - SearchParameter-practitionerrole-organization.json\n",
      "  - SearchParameter-practitionerrole-period.json\n",
      "  - SearchParameter-practitionerrole-practitioner.json\n",
      "  - SearchParameter-practitionerrole-role.json\n",
      "  - SearchParameter-practitionerrole-service.json\n",
      "  - SearchParameter-practitionerrole-specialty.json\n",
      "\n",
      "StructureDefinition (21 files):\n",
      "  - StructureDefinition-accessibility.json\n",
      "  - StructureDefinition-communication-proficiency.json\n",
      "  - StructureDefinition-contactpoint-availabletime.json\n",
      "  - StructureDefinition-delivery-method.json\n",
      "  - StructureDefinition-endpoint-usecase.json\n",
      "  - StructureDefinition-location-reference.json\n",
      "  - StructureDefinition-network-reference.json\n",
      "  - StructureDefinition-newpatients.json\n",
      "  - StructureDefinition-org-description.json\n",
      "  - StructureDefinition-plannet-Endpoint.json\n",
      "  - StructureDefinition-plannet-HealthcareService.json\n",
      "  - StructureDefinition-plannet-InsurancePlan.json\n",
      "  - StructureDefinition-plannet-Location.json\n",
      "  - StructureDefinition-plannet-Network.json\n",
      "  - StructureDefinition-plannet-Organization.json\n",
      "  - StructureDefinition-plannet-OrganizationAffiliation.json\n",
      "  - StructureDefinition-plannet-Practitioner.json\n",
      "  - StructureDefinition-plannet-PractitionerRole.json\n",
      "  - StructureDefinition-practitioner-qualification.json\n",
      "  - StructureDefinition-qualification.json\n",
      "  - StructureDefinition-via-intermediary.json\n",
      "\n",
      "ValueSet (1 files):\n",
      "  - ValueSet-OrganizationAffiliationRoleVS.json\n"
     ]
    }
   ],
   "source": [
    "for category, files in sorted(categorized_files.items()):\n",
    "    print(f\"\\n{category} ({len(files)} files):\")\n",
    "    for file in files:\n",
    "        # Extract just the filename without the /site/ prefix\n",
    "        filename = os.path.basename(file)\n",
    "        print(f\"  - {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(file_path):\n",
    "    \"\"\"\n",
    "    Extract category from file path, handling both /site/ and /html_only/ paths\n",
    "    as well as special cases.\n",
    "    \"\"\"\n",
    "    # Handle special cases first\n",
    "    if file_path.endswith('expansions.json'):\n",
    "        return 'Expansions'\n",
    "    \n",
    "    # Pattern to match category in both /site/ and /html_only/ paths\n",
    "    pattern = r'(?:/site/|/html_only/)([^-]+)-'\n",
    "    match = re.search(pattern, file_path)\n",
    "    \n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    \n",
    "    # If no pattern match, use the filename without extension as category\n",
    "    base_name = os.path.basename(file_path)\n",
    "    category = os.path.splitext(base_name)[0]\n",
    "    return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'] = df['file_name'].apply(get_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get requirements count by category\n",
    "category_counts = df.groupby('category').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get requirements count by file within each category\n",
    "file_counts = df.groupby(['category', 'file_name']).size().reset_index(name='count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_stats = df.groupby('category').agg({\n",
    "    'file_name': 'nunique',  # unique files per category\n",
    "    'requirement': 'count'   # total requirements per category\n",
    "}).reset_index()\n",
    "category_stats['avg_requirements_per_file'] = (\n",
    "    category_stats['requirement'] / category_stats['file_name']\n",
    ").round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>file_name</th>\n",
       "      <th>requirement</th>\n",
       "      <th>avg_requirements_per_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CapabilityStatement</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CodeSystem</td>\n",
       "      <td>19</td>\n",
       "      <td>70</td>\n",
       "      <td>3.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Expansions</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ImplementationGuide</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SearchParameter</td>\n",
       "      <td>89</td>\n",
       "      <td>411</td>\n",
       "      <td>4.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>StructureDefinition</td>\n",
       "      <td>42</td>\n",
       "      <td>143</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ValueSet</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              category  file_name  requirement  avg_requirements_per_file\n",
       "0  CapabilityStatement          2           14                       7.00\n",
       "1           CodeSystem         19           70                       3.68\n",
       "2           Expansions          2            6                       3.00\n",
       "3  ImplementationGuide          1            0                       0.00\n",
       "4      SearchParameter         89          411                       4.62\n",
       "5  StructureDefinition         42          143                       3.40\n",
       "6             ValueSet          3            7                       2.33"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
