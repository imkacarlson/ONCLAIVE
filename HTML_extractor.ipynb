{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting items from HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook extracts elements from HTML files and writes the contents into markdown files. It uses BeautifulSoup to parse the HTML and extract the desired including text, tables, and list elements as well as includes image placeholders. The markdowns are created so that narrative content within the IG can be preserved and concatanated to serve as context for the LLMs. The content is saved in a single markdown file for a specific HTML file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    "from bs4.element import Tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a class `ContentExtractor` to to extract content from HTML files. This class has methods to extract text, tables, and list elements from the HTML. The extracted content is then formatted as markdown and written to a file. The class has methods that also check to see if elements have been processed to avoid duplicates. From images, there is a method (`_extract_images`) to pull the src and alt text and format as markdown image with additional source info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextExtractor:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the context extractor\"\"\"\n",
    "        self.processed_elements = set()\n",
    "        \n",
    "    def _has_been_processed(self, element):\n",
    "        \"\"\"Check if an element has already been processed\"\"\"\n",
    "        if not isinstance(element, Tag):\n",
    "            return False\n",
    "        return element.get('data-processed') == 'true'\n",
    "    \n",
    "    def _mark_processed(self, element):\n",
    "        \"\"\"Mark an element as processed\"\"\"\n",
    "        if isinstance(element, Tag):\n",
    "            element['data-processed'] = 'true'\n",
    "            self.processed_elements.add(element)\n",
    "\n",
    "    def _extract_images(self, element):\n",
    "        \"\"\"\n",
    "        Extract image information including src and alt text\n",
    "        \n",
    "        Args:\n",
    "            element: BeautifulSoup element containing images\n",
    "        Returns:\n",
    "            list: Formatted image information in Markdown\n",
    "        \"\"\"\n",
    "        if self._has_been_processed(element):\n",
    "            return []\n",
    "            \n",
    "        images = []\n",
    "        for img in element.find_all('img', recursive=False):\n",
    "            src = img.get('src', '')\n",
    "            alt = img.get('alt', '')\n",
    "            if src:\n",
    "                # Format as Markdown image with additional source info\n",
    "                images.append(f\"![{alt}]({src})\")\n",
    "                images.append(f\"*Image source: {src}*\")\n",
    "                images.append(f\"*Image description: {alt}*\")\n",
    "                images.append(\"\")  # Add blank line after each image\n",
    "                \n",
    "        self._mark_processed(element)\n",
    "        return images\n",
    "\n",
    "    def _extract_list_items(self, list_element, level=0, parent_type=None):\n",
    "        \"\"\"Extract list items with improved nested list handling\"\"\"\n",
    "        if self._has_been_processed(list_element):\n",
    "            return []\n",
    "            \n",
    "        items = []\n",
    "        for item in list_element.find_all('li', recursive=False):\n",
    "            if not self._has_been_processed(item):\n",
    "                # Get direct text content of the li element (excluding nested list text)\n",
    "                item_text = ''\n",
    "                for content in item.children:\n",
    "                    if isinstance(content, Tag):\n",
    "                        if content.name not in ['ul', 'ol']:\n",
    "                            if content.name == 'img':\n",
    "                                # Handle images within list items\n",
    "                                image_info = self._extract_images(content.parent)\n",
    "                                items.extend([f\"{'    ' * level}{line}\" for line in image_info])\n",
    "                            else:\n",
    "                                item_text += content.get_text(strip=True) + ' '\n",
    "                    else:\n",
    "                        item_text += content.strip() + ' '\n",
    "                item_text = item_text.strip()\n",
    "                \n",
    "                # Format the list item\n",
    "                prefix = '    ' * level\n",
    "                if list_element.name == 'ol':\n",
    "                    items.append(f\"{prefix}1. {item_text}\")\n",
    "                else:\n",
    "                    items.append(f\"{prefix}- {item_text}\")\n",
    "                \n",
    "                # Handle nested lists\n",
    "                nested_lists = item.find_all(['ul', 'ol'], recursive=False)\n",
    "                for nested_list in nested_lists:\n",
    "                    nested_items = []\n",
    "                    for nested_item in nested_list.find_all('li', recursive=False):\n",
    "                        nested_text = nested_item.get_text(strip=True)\n",
    "                        if nested_list.name == 'ol':\n",
    "                            nested_items.append(f\"{prefix}    * {nested_text}\")\n",
    "                        else:\n",
    "                            nested_items.append(f\"{prefix}    * {nested_text}\")\n",
    "                    items.extend(nested_items)\n",
    "                \n",
    "                self._mark_processed(item)\n",
    "        \n",
    "        self._mark_processed(list_element)\n",
    "        return items\n",
    "\n",
    "    def _extract_table(self, table):\n",
    "        \"\"\"Extract table content in Markdown format\"\"\"\n",
    "        if self._has_been_processed(table):\n",
    "            return \"\"\n",
    "            \n",
    "        rows = []\n",
    "        headers = []\n",
    "        \n",
    "        header_row = table.find('thead') or table.find('tr')\n",
    "        if header_row:\n",
    "            headers = [cell.get_text(strip=True) for cell in header_row.find_all(['th', 'td'])]\n",
    "        \n",
    "        for row in table.find_all('tr')[1:] if headers else table.find_all('tr'):\n",
    "            row_data = [cell.get_text(strip=True) for cell in row.find_all(['td', 'th'])]\n",
    "            if any(row_data):\n",
    "                rows.append(row_data)\n",
    "        \n",
    "        table_str = []\n",
    "        if headers:\n",
    "            table_str.append(\"| \" + \" | \".join(headers) + \" |\")\n",
    "            table_str.append(\"|\" + \"|\".join([\" --- \" for _ in headers]) + \"|\")\n",
    "        \n",
    "        for row in rows:\n",
    "            if headers:\n",
    "                row.extend([''] * (len(headers) - len(row)))\n",
    "            table_str.append(\"| \" + \" | \".join(row) + \" |\")\n",
    "        \n",
    "        self._mark_processed(table)\n",
    "        return \"\\n\".join(table_str)\n",
    "\n",
    "    def extract_context(self, html_content):\n",
    "        \"\"\"Extract content with improved list and image handling\"\"\"\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        self.processed_elements.clear()\n",
    "        context_elements = []\n",
    "        \n",
    "        # Remove script and style elements\n",
    "        for script in soup(['script', 'style', 'nav', 'footer']):\n",
    "            script.decompose()\n",
    "        \n",
    "        # Process headers and their content\n",
    "        for header in soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6']):\n",
    "            if not self._has_been_processed(header):\n",
    "                level = int(header.name[1])\n",
    "                header_text = header.get_text().strip()\n",
    "                \n",
    "                if header_text:\n",
    "                    context_elements.append(f\"\\n{'#' * level} {header_text}\\n\")\n",
    "                    self._mark_processed(header)\n",
    "                    \n",
    "                    # Process content until next header\n",
    "                    next_element = header.find_next()\n",
    "                    while next_element and not next_element.name in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:\n",
    "                        if not self._has_been_processed(next_element):\n",
    "                            if next_element.name == 'p':\n",
    "                                # Handle images within paragraphs\n",
    "                                if next_element.find('img'):\n",
    "                                    image_info = self._extract_images(next_element)\n",
    "                                    context_elements.extend(image_info)\n",
    "                                else:\n",
    "                                    text = next_element.get_text().strip()\n",
    "                                    if text:\n",
    "                                        context_elements.append(text)\n",
    "                                        context_elements.append(\"\")\n",
    "                            elif next_element.name in ['ul', 'ol']:\n",
    "                                list_items = self._extract_list_items(next_element)\n",
    "                                if list_items:\n",
    "                                    context_elements.extend(list_items)\n",
    "                                    context_elements.append(\"\")\n",
    "                            elif next_element.name == 'table':\n",
    "                                table_content = self._extract_table(next_element)\n",
    "                                if table_content:\n",
    "                                    context_elements.append(table_content)\n",
    "                                    context_elements.append(\"\")\n",
    "                        \n",
    "                        next_element = next_element.find_next()\n",
    "\n",
    "        # Process any remaining top-level images\n",
    "        for img_container in soup.find_all('p'):\n",
    "            if img_container.find('img') and not self._has_been_processed(img_container):\n",
    "                image_info = self._extract_images(img_container)\n",
    "                if image_info:\n",
    "                    context_elements.extend(image_info)\n",
    "        \n",
    "        # Clean up repeated empty lines\n",
    "        cleaned_elements = []\n",
    "        prev_empty = False\n",
    "        for element in context_elements:\n",
    "            if element.strip() == \"\":\n",
    "                if not prev_empty:\n",
    "                    cleaned_elements.append(element)\n",
    "                    prev_empty = True\n",
    "            else:\n",
    "                cleaned_elements.append(element)\n",
    "                prev_empty = False\n",
    "        \n",
    "        return cleaned_elements\n",
    "\n",
    "    def save_context(self, context_elements, output_file):\n",
    "        \"\"\"Save context to Markdown file\"\"\"\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            for element in context_elements:\n",
    "                f.write(f\"{element}\\n\")\n",
    "\n",
    "    def process_html_file(self, input_file, output_file):\n",
    "        \"\"\"Process HTML file to Markdown\"\"\"\n",
    "        try:\n",
    "            output_file = os.path.splitext(output_file)[0] + '.md'\n",
    "            \n",
    "            with open(input_file, 'r', encoding='utf-8') as f:\n",
    "                html_content = f.read()\n",
    "            \n",
    "            context_elements = self.extract_context(html_content)\n",
    "            self.save_context(context_elements, output_file)\n",
    "            self._display_summary(input_file, output_file, len(context_elements))\n",
    "            \n",
    "            return context_elements\n",
    "            \n",
    "        except Exception as e:\n",
    "            display(HTML(f'<div style=\"color: red;\">Error processing file: {str(e)}</div>'))\n",
    "            return []\n",
    "\n",
    "    def process_directory(self, input_dir, output_dir):\n",
    "        \"\"\"Process directory of HTML files\"\"\"\n",
    "        Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for file in Path(input_dir).glob('*.html'):\n",
    "            output_file = Path(output_dir) / f\"{file.stem}.md\"\n",
    "            self.process_html_file(str(file), str(output_file))\n",
    "\n",
    "    def _display_summary(self, input_file, output_file, num_elements):\n",
    "        \"\"\"Display processing summary\"\"\"\n",
    "        summary_html = f\"\"\"\n",
    "        <div style=\"background-color: #f0f0f0; padding: 10px; border-radius: 5px; margin: 10px 0;\">\n",
    "            <p><strong>Processed file:</strong> {os.path.basename(input_file)}</p>\n",
    "            <p><strong>Output saved to:</strong> {os.path.basename(output_file)}</p>\n",
    "            <p><strong>Extracted elements:</strong> {num_elements}</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(summary_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ContentExtractor` is called by creating an instance of the class and then calling the `process_html_file` or `process_directory` method. The `process_html_file` method takes two arguments: the path to the input HTML file and the desired name of the output Markdown file. The `process_directory` method takes two arguments: the path to the input directory containing HTML files and the path to the output directory where the Markdown files will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #f0f0f0; padding: 10px; border-radius: 5px; margin: 10px 0;\">\n",
       "            <p><strong>Processed file:</strong> index.html</p>\n",
       "            <p><strong>Output saved to:</strong> context.md</p>\n",
       "            <p><strong>Extracted elements:</strong> 65</p>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "extractor = ContextExtractor()\n",
    "context = extractor.process_html_file(\n",
    "    input_file='/Users/amathur/Documents/ONCLAIVE/onclaive-aanchalwip/PlanNet/site/index.html',\n",
    "    output_file='context'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Element 1:\n",
      "\n",
      "## Home\n",
      "\n",
      "\n",
      "Element 2:\n",
      "| Official URL:http://hl7.org/fhir/us/davinci-pdex-plan-net/ImplementationGuide/hl7.fhir.us.davinci-pdex-plan-net | Version:1.1.0 |\n",
      "| --- | --- |\n",
      "| Active\n",
      "          \n",
      "            as of 2022-04-04 | Com...\n",
      "\n",
      "Element 3:\n",
      "\n",
      "\n",
      "Element 4:\n",
      "\n",
      "### PDEX Payer Network Implementation Guide\n",
      "\n",
      "\n",
      "Element 5:\n",
      "\n",
      "#### Introduction\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, element in enumerate(context[:5]):  # Show first 5 elements\n",
    "    print(f\"\\nElement {i+1}:\")\n",
    "    print(element[:200] + \"...\" if len(element) > 200 else element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
