{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What do LLMs know about Plan Net IG without any additional context?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to test understanding of LLM models **on MITRE's AI Platform (AIP)**  and endpoints regarding their understanding of the PlanNet Implementation Guide. Conducting this baseline experiment will demonstarate the inherent knowledge of the LLMs and serve as a control in our experiments.\n",
    "\n",
    "Were the models trained on the PlanNet IG? To do this we will ask 10 questions about the PlanNet IG and see how the models respond.\n",
    "\n",
    "For more information on MITRE's AIP:\n",
    "\n",
    "https://ai-platform.pages.mitre.org/resources/llm-endpoints/#using-the-endpoint-api\n",
    "\n",
    "The best available models for use are \n",
    "- Mixtral-8x22B-Instruct-v0.1\n",
    "- Meta-Llama-3.1-70B-Instruct\n",
    "- Codestral-22B-v0.1 (Mistral-based)\n",
    "- CohereForAI/c4ai-command-r-plus\n",
    "\n",
    "Be sure to check the outages page to check which models are avaliable:\n",
    "\n",
    "https://uptime.k8s.aip.mitre.org/status/aip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as gemini\n",
    "from anthropic import Anthropic\n",
    "from openai import OpenAI\n",
    "import io, threading, time, re, json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import httpx\n",
    "from IPython.display import display, Markdown\n",
    "from datetime import datetime\n",
    "from huggingface_hub import InferenceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "claude_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
    "OpenAI.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is our list of questions that will be asked independently of each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"What is the purpose of the FHIR DaVinci PlanNet Implementation Guide?\",\n",
    "    \"Who are the intended users and actors of the FHIR DaVinci PlanNet Implementation Guide?\",\n",
    "    \"Are there one or more workflows defined in the FHIR DaVinci PDex Plan Net Implementation Guide? Please use all the information you know.\",\n",
    "    \"What data is being exchanged in the FHIR DaVinci PDex Plan Net Implementation Guide and why?\",\n",
    "    \"How is that data represented by the resources and profiles in the FHIR DaVinci PDex Plan Net Implementation Guide?\",\n",
    "    \"What actions (REST/CRUD) or operations can be used in the FHIR DaVinci PDex Plan Net Implementation Guide?\",\n",
    "    \"What are all the mandatory requirements and rules from the DaVinci PDex Plan Net Implementation Guide for compliant implementations?\",\n",
    "    \"What are all the optional requirements and rules from the DaVinci PDex Plan Net Implementation Guide for compliant implementations?\",\n",
    "    \"How would you create a test plan for the FHIR DaVinci PDex Plan Net Implementation Guide?\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions are used to run querries and display results within this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to add sleep pauses\n",
    "def heartbeat(stop_event, start_time):\n",
    "    \"\"\"Prints elapsed time periodically until stopped.\"\"\"\n",
    "    while not stop_event.is_set():\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"... still processing ({elapsed:.1f}s elapsed)\")\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_qa(json_file_path):\n",
    "    \"\"\"\n",
    "    Display just the questions and answers in a clean format\n",
    "    \"\"\"\n",
    "    with open(json_file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    for question, response in data['results'].items():\n",
    "        display(Markdown(f\"## {question}\\n\"))\n",
    "        display(Markdown(f\"{response}\\n\"))\n",
    "        display(Markdown(\"---\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistralai/Mixtral-8x22B-Instruct-v0.1\n",
    "\n",
    "https://mixtral-8x22b.k8s.aip.mitre.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"Mixtral_responses\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mixtral_client():\n",
    "    return InferenceClient(model=\"https://mixtral-8x22b.k8s.aip.mitre.org\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_mixtral(client, question, max_retries=3):\n",
    "    \"\"\"Ask Mixtral a question with retry logic\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            messages = [{\"role\": \"user\", \"content\": question}]\n",
    "            response = client.chat_completion(messages, max_tokens=60000)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                raise e\n",
    "            print(f\"Attempt {attempt + 1} failed. Retrying...\")\n",
    "            time.sleep(2 ** attempt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_all_questions_mixtral():\n",
    "    \"\"\"Run analysis for all questions and save results with timestamp\"\"\"    \n",
    "    results = {}\n",
    "    client = create_mixtral_client()\n",
    "        \n",
    "    # Generate timestamp for the filename\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_file = os.path.join(output_dir, f\"mixtral_plannet_analysis_{timestamp}.json\")\n",
    "    \n",
    "    for question in questions:\n",
    "        print(f\"\\nAnalyzing question: {question}\")\n",
    "        response = ask_mixtral(client, question)\n",
    "        results[question] = response\n",
    "        \n",
    "        # Save results after each question\n",
    "        with open(output_file, 'w') as f:\n",
    "            final_output = {\n",
    "                \"metadata\": {\n",
    "                    \"timestamp\": timestamp,\n",
    "                    \"generation_date\": datetime.now().isoformat()\n",
    "                },\n",
    "                \"results\": results\n",
    "            }\n",
    "            json.dump(final_output, f, indent=2)\n",
    "            \n",
    "        time.sleep(2)  # Small delay between questions\n",
    "        \n",
    "    print(f\"\\nResults saved to: {output_file}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing question: What is the purpose of the FHIR DaVinci PlanNet Implementation Guide?\n",
      "\n",
      "Analyzing question: Who are the intended users and actors of the FHIR DaVinci PlanNet Implementation Guide?\n",
      "\n",
      "Analyzing question: Are there one or more workflows defined in the FHIR DaVinci PDex Plan Net Implementation Guide? Please use all the information you know.\n",
      "\n",
      "Analyzing question: What data is being exchanged in the FHIR DaVinci PDex Plan Net Implementation Guide and why?\n",
      "\n",
      "Analyzing question: How is that data represented by the resources and profiles in the FHIR DaVinci PDex Plan Net Implementation Guide?\n",
      "\n",
      "Analyzing question: What actions (REST/CRUD) or operations can be used in the FHIR DaVinci PDex Plan Net Implementation Guide?\n",
      "\n",
      "Analyzing question: What are all the mandatory requirements and rules from the DaVinci PDex Plan Net Implementation Guide for compliant implementations?\n",
      "\n",
      "Analyzing question: What are all the optional requirements and rules from the DaVinci PDex Plan Net Implementation Guide for compliant implementations?\n",
      "\n",
      "Analyzing question: How would you create a test plan for the FHIR DaVinci PDex Plan Net Implementation Guide?\n",
      "\n",
      "Results saved to: Mixtral_responses/mixtral_plannet_analysis_20241121_120503.json\n"
     ]
    }
   ],
   "source": [
    "results = analyze_all_questions_mixtral()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## meta-llama/Llama-3.1-70B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"Llama_responses\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_llama_client():\n",
    "    return InferenceClient(model=\"https://llama3-70b.k8s.aip.mitre.org\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_llama(client, question, max_retries=3):\n",
    "    \"\"\"Ask Llama a question with retry logic\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            messages = [{\"role\": \"user\", \"content\": question}]\n",
    "            response = client.chat_completion(messages, max_tokens=4192)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                raise e\n",
    "            print(f\"Attempt {attempt + 1} failed. Retrying...\")\n",
    "            time.sleep(2 ** attempt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_all_questions_llama():\n",
    "    \"\"\"Run analysis for all questions and save results with timestamp\"\"\"    \n",
    "    results = {}\n",
    "    client = create_llama_client()\n",
    "        \n",
    "    # Generate timestamp for the filename\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_file = os.path.join(output_dir, f\"llama_plannet_analysis_{timestamp}.json\")\n",
    "    \n",
    "    for question in questions:\n",
    "        print(f\"\\nAnalyzing question: {question}\")\n",
    "        response = ask_llama(client, question)\n",
    "        results[question] = response\n",
    "        \n",
    "        # Save results after each question\n",
    "        with open(output_file, 'w') as f:\n",
    "            final_output = {\n",
    "                \"metadata\": {\n",
    "                    \"timestamp\": timestamp,\n",
    "                    \"generation_date\": datetime.now().isoformat()\n",
    "                },\n",
    "                \"results\": results\n",
    "            }\n",
    "            json.dump(final_output, f, indent=2)\n",
    "            \n",
    "        time.sleep(2)  # Small delay between questions\n",
    "        \n",
    "    print(f\"\\nResults saved to: {output_file}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing question: What is the purpose of the FHIR DaVinci PlanNet Implementation Guide?\n",
      "\n",
      "Analyzing question: Who are the intended users and actors of the FHIR DaVinci PlanNet Implementation Guide?\n",
      "\n",
      "Analyzing question: Are there one or more workflows defined in the FHIR DaVinci PDex Plan Net Implementation Guide? Please use all the information you know.\n",
      "\n",
      "Analyzing question: What data is being exchanged in the FHIR DaVinci PDex Plan Net Implementation Guide and why?\n",
      "\n",
      "Analyzing question: How is that data represented by the resources and profiles in the FHIR DaVinci PDex Plan Net Implementation Guide?\n",
      "\n",
      "Analyzing question: What actions (REST/CRUD) or operations can be used in the FHIR DaVinci PDex Plan Net Implementation Guide?\n",
      "\n",
      "Analyzing question: What are all the mandatory requirements and rules from the DaVinci PDex Plan Net Implementation Guide for compliant implementations?\n",
      "\n",
      "Analyzing question: What are all the optional requirements and rules from the DaVinci PDex Plan Net Implementation Guide for compliant implementations?\n",
      "\n",
      "Analyzing question: How would you create a test plan for the FHIR DaVinci PDex Plan Net Implementation Guide?\n",
      "\n",
      "Results saved to: Llama_responses/llama_plannet_analysis_20241121_121942.json\n"
     ]
    }
   ],
   "source": [
    "results = analyze_all_questions_llama()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mistralai/Codestral-22B-v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"Codestral_responses\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_codestral_client():\n",
    "    return InferenceClient(model=\"https://codestral-22b.k8s.aip.mitre.org\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_codestral(client, question, max_retries=3):\n",
    "    \"\"\"Ask Codestral a question with retry logic\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            messages = [{\"role\": \"user\", \"content\": question}]\n",
    "            response = client.chat_completion(messages, max_tokens=4192)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                raise e\n",
    "            print(f\"Attempt {attempt + 1} failed. Retrying...\")\n",
    "            time.sleep(2 ** attempt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_all_questions_codestral():\n",
    "    \"\"\"Run analysis for all questions and save results with timestamp\"\"\"    \n",
    "    results = {}\n",
    "    client = create_codestral_client()\n",
    "        \n",
    "    # Generate timestamp for the filename\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_file = os.path.join(output_dir, f\"codestral_plannet_analysis_{timestamp}.json\")\n",
    "    \n",
    "    for question in questions:\n",
    "        print(f\"\\nAnalyzing question: {question}\")\n",
    "        response = ask_llama(client, question)\n",
    "        results[question] = response\n",
    "        \n",
    "        # Save results after each question\n",
    "        with open(output_file, 'w') as f:\n",
    "            final_output = {\n",
    "                \"metadata\": {\n",
    "                    \"timestamp\": timestamp,\n",
    "                    \"generation_date\": datetime.now().isoformat()\n",
    "                },\n",
    "                \"results\": results\n",
    "            }\n",
    "            json.dump(final_output, f, indent=2)\n",
    "            \n",
    "        time.sleep(2)  # Small delay between questions\n",
    "        \n",
    "    print(f\"\\nResults saved to: {output_file}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing question: What is the purpose of the FHIR DaVinci PlanNet Implementation Guide?\n",
      "\n",
      "Analyzing question: Who are the intended users and actors of the FHIR DaVinci PlanNet Implementation Guide?\n",
      "\n",
      "Analyzing question: Are there one or more workflows defined in the FHIR DaVinci PDex Plan Net Implementation Guide? Please use all the information you know.\n",
      "\n",
      "Analyzing question: What data is being exchanged in the FHIR DaVinci PDex Plan Net Implementation Guide and why?\n",
      "\n",
      "Analyzing question: How is that data represented by the resources and profiles in the FHIR DaVinci PDex Plan Net Implementation Guide?\n",
      "\n",
      "Analyzing question: What actions (REST/CRUD) or operations can be used in the FHIR DaVinci PDex Plan Net Implementation Guide?\n",
      "\n",
      "Analyzing question: What are all the mandatory requirements and rules from the DaVinci PDex Plan Net Implementation Guide for compliant implementations?\n",
      "\n",
      "Analyzing question: What are all the optional requirements and rules from the DaVinci PDex Plan Net Implementation Guide for compliant implementations?\n",
      "\n",
      "Analyzing question: How would you create a test plan for the FHIR DaVinci PDex Plan Net Implementation Guide?\n",
      "\n",
      "Results saved to: Codestral_responses/codestral_plannet_analysis_20241121_122248.json\n"
     ]
    }
   ],
   "source": [
    "results = analyze_all_questions_codestral()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CohereForAI/c4ai-command-r-plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"Cohere_responses\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cohere_client():\n",
    "    return InferenceClient(model=\"https://command-rplus.k8s.aip.mitre.org\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_cohere(client, question, max_retries=3):\n",
    "    \"\"\"Ask Cohere a question with retry logic\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            messages = [{\"role\": \"user\", \"content\": question}]\n",
    "            response = client.chat_completion(messages, max_tokens=4192)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                raise e\n",
    "            print(f\"Attempt {attempt + 1} failed. Retrying...\")\n",
    "            time.sleep(2 ** attempt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_all_questions_cohere():\n",
    "    \"\"\"Run analysis for all questions and save results with timestamp\"\"\"    \n",
    "    results = {}\n",
    "    client = create_cohere_client()\n",
    "        \n",
    "    # Generate timestamp for the filename\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_file = os.path.join(output_dir, f\"cohere_plannet_analysis_{timestamp}.json\")\n",
    "    \n",
    "    for question in questions:\n",
    "        print(f\"\\nAnalyzing question: {question}\")\n",
    "        response = ask_llama(client, question)\n",
    "        results[question] = response\n",
    "        \n",
    "        # Save results after each question\n",
    "        with open(output_file, 'w') as f:\n",
    "            final_output = {\n",
    "                \"metadata\": {\n",
    "                    \"timestamp\": timestamp,\n",
    "                    \"generation_date\": datetime.now().isoformat()\n",
    "                },\n",
    "                \"results\": results\n",
    "            }\n",
    "            json.dump(final_output, f, indent=2)\n",
    "            \n",
    "        time.sleep(2)  # Small delay between questions\n",
    "        \n",
    "    print(f\"\\nResults saved to: {output_file}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing question: What is the purpose of the FHIR DaVinci PlanNet Implementation Guide?\n",
      "\n",
      "Analyzing question: Who are the intended users and actors of the FHIR DaVinci PlanNet Implementation Guide?\n",
      "\n",
      "Analyzing question: Are there one or more workflows defined in the FHIR DaVinci PDex Plan Net Implementation Guide? Please use all the information you know.\n",
      "\n",
      "Analyzing question: What data is being exchanged in the FHIR DaVinci PDex Plan Net Implementation Guide and why?\n",
      "\n",
      "Analyzing question: How is that data represented by the resources and profiles in the FHIR DaVinci PDex Plan Net Implementation Guide?\n",
      "\n",
      "Analyzing question: What actions (REST/CRUD) or operations can be used in the FHIR DaVinci PDex Plan Net Implementation Guide?\n",
      "\n",
      "Analyzing question: What are all the mandatory requirements and rules from the DaVinci PDex Plan Net Implementation Guide for compliant implementations?\n",
      "\n",
      "Analyzing question: What are all the optional requirements and rules from the DaVinci PDex Plan Net Implementation Guide for compliant implementations?\n",
      "\n",
      "Analyzing question: How would you create a test plan for the FHIR DaVinci PDex Plan Net Implementation Guide?\n",
      "\n",
      "Results saved to: Cohere_responses/cohere_plannet_analysis_20241121_122620.json\n"
     ]
    }
   ],
   "source": [
    "results = analyze_all_questions_cohere()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
