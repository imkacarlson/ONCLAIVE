{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Claude Requirements Extraction\n",
    "This script aims to develop a structure to send large amounts of text/content to LLM APIs through multiple calls. The current approach takes in all JSON files from the Plan Net IG and key narrative information in markdown form (formerly extracted from HTML files). The script then analyzes each type of information in batches, and creates a meta-list of all requirements extracted from those documents. The goal is to identify if this approach can produce all technical information at an appropriate level of deatil that an LLM would need to know to help design a test kit for a given IG.\n",
    "\n",
    "First attempts: We were able to run through the script fully using the Claude API with all JSONs and markdown content. The process took over 93 minutes. The output requirements list is saved in the files (processed_output/test_requirements_claude1.json and .csv). \n",
    "\n",
    "In progress: \n",
    "- Adding images back in, revising the prompting based on Inferno requirements extraction process documentation\n",
    "- Comparing LLM results\n",
    "- Reviewing LangChain capabilities to improve document loading and summary quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script Organization:\n",
    "1. Imports and Basic Setup\n",
    "2. API Configuration\n",
    "3. File Processing\n",
    "4. Rate Limiting\n",
    "5. Batch Processing/API Call Functions\n",
    "7. Main Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. IMPORTS AND BASIC SETUP\n",
    "import base64\n",
    "import json\n",
    "import logging\n",
    "from typing import List, Dict, Tuple, Union, Optional, Any\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "from IPython.display import Image\n",
    "import math\n",
    "import io\n",
    "import re\n",
    "import pandas as pd\n",
    "from json_repair import repair_json\n",
    "from langchain_community.document_loaders import BSHTMLLoader\n",
    "import shutil\n",
    "from dotenv import load_dotenv\n",
    "import httpx\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tenacity import retry, wait_exponential, stop_after_attempt, retry_if_exception_type\n",
    "from anthropic import RateLimitError\n",
    "from anthropic import Anthropic\n",
    "import google.generativeai as gemini\n",
    "from openai import OpenAI\n",
    "import httpx\n",
    "\n",
    "\n",
    "# Basic setup\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "load_dotenv()\n",
    "\n",
    "# Constants\n",
    "CERT_PATH = '/opt/homebrew/etc/openssl@3/cert.pem'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_CONFIGS = {\n",
    "    \"claude\": {\n",
    "        \"model_name\": \"claude-3-5-sonnet-20240620\",\n",
    "        \"max_tokens\": 8192,\n",
    "        \"temperature\": 0.7,\n",
    "        \"batch_size\": 3,\n",
    "        \"delay_between_chunks\": 2,\n",
    "        \"delay_between_batches\": 10,\n",
    "        \"requests_per_minute\": 25,\n",
    "        \"max_requests_per_day\": 5000,\n",
    "        \"delay_between_requests\": 2\n",
    "    }\n",
    "}\n",
    "\n",
    "SYSTEM_PROMPTS = {\n",
    "    \"claude\": \"\"\"You are a seasoned Healthcare Integration Test Engineer \n",
    "                analyzing a FHIR Implementation Guide to extract precise testable requirements.\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulling in files of interest\n",
    "Sourcing JSON files from the IG, copying them from full-ig directory into json_only folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_json_files(source_folder='full-ig/site', destination_folder='full-ig/json_only'):\n",
    "    \"\"\"Copy and filter relevant JSON files\"\"\"\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    json_files = []\n",
    "    for file_name in os.listdir(source_folder):\n",
    "        if (file_name.endswith('.json') and \n",
    "            not any(file_name.endswith(ext) for ext in [\n",
    "                '.ttl.json', '.jsonld.json', '.xml.json', '.change.history.json'\n",
    "            ])):\n",
    "            json_files.append(file_name)\n",
    "            shutil.copy(os.path.join(source_folder, file_name), destination_folder)\n",
    "            \n",
    "    logging.info(f\"Copied {len(json_files)} JSON files to {destination_folder}\")\n",
    "    return json_files\n",
    "\n",
    "\n",
    "def prepare_json_for_processing(json_file_path: str) -> Union[dict, list]:\n",
    "    \"\"\"Read and prepare JSON file for processing, handling UTF-8 BOM\"\"\"\n",
    "    try:\n",
    "        # First try reading with utf-8-sig encoding to handle BOM\n",
    "        with open(json_file_path, 'r', encoding='utf-8-sig') as f:\n",
    "            data = json.load(f)\n",
    "            return data['entry'] if isinstance(data, dict) and 'entry' in data else data\n",
    "    except (json.JSONDecodeError, UnicodeError) as e:\n",
    "        # If that fails, try with regular utf-8\n",
    "        try:\n",
    "            with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                return data['entry'] if isinstance(data, dict) and 'entry' in data else data\n",
    "        except (json.JSONDecodeError, UnicodeError) as e:\n",
    "            # If the file is corrupted, log it and skip\n",
    "            logging.error(f\"Error processing {json_file_path}: {str(e)}\")\n",
    "            return []  # Return empty list for corrupted files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Files for LLM\n",
    "\n",
    "Because we have so many JSONs, we cannot feed them all to an LLM at once. These functions split combined JSONs into chunks that can fit in one LLM call. We included this feature to try and maintain summarization quality- the LLM should receive all relevant information together instead of in pieces, to help it understand what it is receiving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_json(json_data: Union[dict, list], max_size: int = 2000) -> List[list]:\n",
    "    \"\"\"Split JSON into chunks while maintaining object integrity\"\"\"\n",
    "    if isinstance(json_data, dict):\n",
    "        json_data = [json_data]\n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_size = 0\n",
    "    \n",
    "    for item in json_data:\n",
    "        item_size = len(json.dumps(item))\n",
    "        if item_size > max_size:\n",
    "            if current_chunk:\n",
    "                chunks.append(current_chunk)\n",
    "            chunks.append([item])\n",
    "            current_chunk = []\n",
    "            current_size = 0\n",
    "        elif current_size + item_size > max_size:\n",
    "            chunks.append(current_chunk)\n",
    "            current_chunk = [item]\n",
    "            current_size = item_size\n",
    "        else:\n",
    "            current_chunk.append(item)\n",
    "            current_size += item_size\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk)\n",
    "    return chunks\n",
    "\n",
    "def clean_markdown(text: str) -> str:\n",
    "    \"\"\"Clean markdown content\"\"\"\n",
    "    text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)\n",
    "    text = re.sub(r'<!--.*?-->', '', text, flags=re.DOTALL)\n",
    "    text = re.sub(r'\\.{2,}', '.', text)\n",
    "    text = re.sub(r'\\\\(.)', r'\\1', text)\n",
    "    text = re.sub(r'\\|', ' ', text)\n",
    "    text = re.sub(r'[-\\s]*\\n[-\\s]*', '\\n', text)\n",
    "    return text.strip()\n",
    "\n",
    "def split_markdown(content: str, max_size: int = 2000) -> List[str]:\n",
    "    \"\"\"Split markdown into manageable chunks\"\"\"\n",
    "    chunks = []\n",
    "    lines = content.split('\\n')\n",
    "    current_chunk = []\n",
    "    current_size = 0\n",
    "    \n",
    "    for line in lines:\n",
    "        line_size = len(line)\n",
    "        if current_size + line_size > max_size:\n",
    "            if current_chunk:\n",
    "                chunks.append('\\n'.join(current_chunk))\n",
    "            current_chunk = [line]\n",
    "            current_size = line_size\n",
    "        else:\n",
    "            current_chunk.append(line)\n",
    "            current_size += line_size\n",
    "            \n",
    "    if current_chunk:\n",
    "        chunks.append('\\n'.join(current_chunk))\n",
    "    return chunks\n",
    "\n",
    "def consolidate_jsons(base_directory: str = 'full-ig/json_only'):\n",
    "    \"\"\"Consolidate related JSON files while maintaining integrity\"\"\"\n",
    "    subdirs = [d for d in os.listdir(base_directory) \n",
    "              if os.path.isdir(os.path.join(base_directory, d))]\n",
    "    \n",
    "    for subdir in subdirs:\n",
    "        folder_path = os.path.join(base_directory, subdir)\n",
    "        combined_data = []\n",
    "        \n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith('.json'):\n",
    "                try:\n",
    "                    with open(os.path.join(folder_path, filename), 'r') as f:\n",
    "                        json_content = json.load(f)\n",
    "                        if isinstance(json_content, dict) and 'entry' in json_content:\n",
    "                            combined_data.extend(json_content['entry'])\n",
    "                        else:\n",
    "                            combined_data.append(json_content)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    logging.error(f\"Error decoding JSON from {filename}: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        if combined_data:\n",
    "            output_filename = f\"{subdir}_combined.json\"\n",
    "            output_path = os.path.join(base_directory, output_filename)\n",
    "            try:\n",
    "                with open(output_path, 'w') as outfile:\n",
    "                    json.dump({\n",
    "                        \"resourceType\": subdir,\n",
    "                        \"total\": len(combined_data),\n",
    "                        \"entry\": combined_data\n",
    "                    }, outfile, indent=2)\n",
    "                logging.info(f\"Created {output_filename} with {len(combined_data)} entries\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error writing {output_filename}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Rate Limiting & Safe Call Functions\n",
    "\n",
    "Because of the amount of content we are sending to APIs, we need to include rate limiting in our prompt chaining process to avoid hitting rate limits. This includes a function to create a reate limiter and to make calls to the Claude LLM with the rate limiter included. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rate_limiter():\n",
    "    \"\"\"Create a rate limiter state dictionary for all APIs\"\"\"\n",
    "    return {\n",
    "        api: {\n",
    "            'requests': [],\n",
    "            'daily_requests': 0,\n",
    "            'last_reset': time.time()\n",
    "        }\n",
    "        for api in API_CONFIGS.keys()\n",
    "    }\n",
    "\n",
    "def check_rate_limits(rate_limiter: dict, api: str):\n",
    "    \"\"\"Check and wait if rate limits would be exceeded\"\"\"\n",
    "    if api not in rate_limiter:\n",
    "        raise ValueError(f\"Unknown API: {api}\")\n",
    "        \n",
    "    now = time.time()\n",
    "    state = rate_limiter[api]\n",
    "    config = API_CONFIGS[api]\n",
    "    \n",
    "    # Reset daily counts if needed\n",
    "    day_seconds = 24 * 60 * 60\n",
    "    if now - state['last_reset'] >= day_seconds:\n",
    "        state['daily_requests'] = 0\n",
    "        state['last_reset'] = now\n",
    "    \n",
    "    # Check daily limit\n",
    "    if state['daily_requests'] >= config['max_requests_per_day']:\n",
    "        raise Exception(f\"{api} daily request limit exceeded\")\n",
    "    \n",
    "    # Remove old requests outside the current minute\n",
    "    state['requests'] = [\n",
    "        req_time for req_time in state['requests']\n",
    "        if now - req_time < 60\n",
    "    ]\n",
    "    \n",
    "    # Wait if at rate limit\n",
    "    if len(state['requests']) >= config['requests_per_minute']:\n",
    "        sleep_time = 60 - (now - state['requests'][0])\n",
    "        if sleep_time > 0:\n",
    "            time.sleep(sleep_time)\n",
    "        state['requests'] = state['requests'][1:]\n",
    "    \n",
    "    # Add minimum delay between requests\n",
    "    if state['requests'] and now - state['requests'][-1] < config['delay_between_requests']:\n",
    "        time.sleep(config['delay_between_requests'])\n",
    "    \n",
    "    # Record this request\n",
    "    state['requests'].append(now)\n",
    "    state['daily_requests'] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(\n",
    "    wait=wait_exponential(multiplier=1, min=4, max=60),\n",
    "    stop=stop_after_attempt(5),\n",
    "    retry=retry_if_exception_type((RateLimitError, TimeoutError))\n",
    ")\n",
    "def make_api_request(client, api_type: str, content: Union[str, dict, list], rate_limit_func) -> str:\n",
    "    \"\"\"Make rate-limited API request with retries\"\"\"\n",
    "    rate_limit_func()\n",
    "    \n",
    "    config = API_CONFIGS[api_type]\n",
    "    formatted_content = format_content_for_api(content, api_type)\n",
    "    \n",
    "    try:\n",
    "        if api_type == \"claude\":\n",
    "            response = client.messages.create(\n",
    "                model=config[\"model_name\"],\n",
    "                max_tokens=config[\"max_tokens\"],\n",
    "                messages=[{\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": formatted_content\n",
    "                }],\n",
    "                system=SYSTEM_PROMPTS[api_type]\n",
    "            )\n",
    "            return response.content[0].text\n",
    "            \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in {api_type} API request: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing Functions\n",
    "This set of functions allows for analysis of batches of each information type (e.g., JSONs, markdown, and images) from individual files to extract requirements, and then sending those combined requirements lists to the LLM at once to ask for one meta-summarization of requirements. The requirements are formatted as a CSV with relevant metadata, which is saved as an output file for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_content_batch(api_type: str, contents: List[Union[str, dict]], \n",
    "                        config: dict, client, rate_limit_func) -> List[str]:\n",
    "    \"\"\"Process a batch of content with rate limiting\"\"\"\n",
    "    results = []\n",
    "    for content in contents:\n",
    "        result = make_api_request(client, api_type, content, rate_limit_func)\n",
    "        results.append(result)\n",
    "        time.sleep(config[\"delay_between_chunks\"])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_requirements_extraction_prompt(content: Union[str, dict, list]) -> str:\n",
    "    \"\"\"Create a prompt that aligns with Inferno's requirements extraction process\"\"\"\n",
    "    \n",
    "    return f\"\"\"Analyze this FHIR Implementation Guide content to extract precise requirements following these guidelines:\n",
    "\n",
    "For each requirement you identify, provide:\n",
    "\n",
    "1. REQUIREMENT TEXT\n",
    "- Extract direct quotes from the source\n",
    "- For compound requirements, split into atomic requirements\n",
    "- Maintain context when splitting\n",
    "- Use [...] for added clarifications\n",
    "- Use ... for removed text\n",
    "- Format using markdown syntax for code blocks, italics, etc.\n",
    "\n",
    "2. REQUIREMENT METADATA\n",
    "- Conformance Level (SHALL, SHOULD, MAY, SHOULD NOT, SHALL NOT)\n",
    "- Actor(s) the requirement applies to\n",
    "- Whether the requirement is conditional (True/False)\n",
    "- Any sub-requirements or referenced requirements\n",
    "\n",
    "3. SOURCE TRACEABILITY\n",
    "- Note the specific section or location this requirement comes from\n",
    "- For JSON content, note the specific resource type and element\n",
    "\n",
    "When analyzing content, focus on:\n",
    "\n",
    "a) Making requirements atomic and testable\n",
    "b) Maintaining the original text while adding necessary context\n",
    "c) Identifying implicit requirements for each actor\n",
    "d) Distinguishing between conjunctive (\"and\") and disjunctive (\"or\") requirements\n",
    "e) Capturing terminology bindings and must-support elements\n",
    "f) Noting RESTful API conformance requirements\n",
    "g) Identifying conditional requirements\n",
    "\n",
    "Content to analyze:\n",
    "{json.dumps(content, indent=2) if isinstance(content, (dict, list)) else content}\n",
    "\n",
    "Format each requirement as:\n",
    "```\n",
    "Requirement Text: <quoted text with [...] for clarifications and ... for elisions>\n",
    "Conformance: <conformance level>\n",
    "Actor: <actor name(s)>\n",
    "Conditional: <True/False>\n",
    "Sub-Requirements: <list of referenced requirements if any>\n",
    "Source: <specific location in documentation>\n",
    "```\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_llm_requirements_output(output: str) -> List[Dict]:\n",
    "    \"\"\"Process LLM output into standardized requirements format\"\"\"\n",
    "    requirements = []\n",
    "    current_req = {}\n",
    "    \n",
    "    # Split output into individual requirements\n",
    "    req_blocks = output.split('\\n\\n')\n",
    "    \n",
    "    for block in req_blocks:\n",
    "        if block.strip().startswith('Requirement Text:'):\n",
    "            # Save previous requirement if it exists\n",
    "            if current_req:\n",
    "                requirements.append(current_req)\n",
    "                current_req = {}\n",
    "            \n",
    "            # Parse new requirement\n",
    "            lines = block.strip().split('\\n')\n",
    "            for line in lines:\n",
    "                if ': ' in line:\n",
    "                    key, value = line.split(': ', 1)\n",
    "                    key = key.lower().replace(' ', '_')\n",
    "                    current_req[key] = value.strip()\n",
    "    \n",
    "    # Add final requirement\n",
    "    if current_req:\n",
    "        requirements.append(current_req)\n",
    "        \n",
    "    return requirements\n",
    "\n",
    "def save_requirements_to_csv(requirements: List[Dict], output_file: str):\n",
    "    \"\"\"Save extracted requirements to CSV format matching Inferno's structure\"\"\"\n",
    "    df = pd.DataFrame(requirements)\n",
    "    \n",
    "    # Rename columns to match Inferno's format\n",
    "    column_mapping = {\n",
    "        'requirement_text': 'Requirement',\n",
    "        'conformance': 'Conformance',\n",
    "        'actor': 'Actor',\n",
    "        'conditional': 'Conditionality',\n",
    "        'source': 'URL',\n",
    "        'sub_requirements': 'Sub-Requirement(s)'\n",
    "    }\n",
    "    \n",
    "    df = df.rename(columns=column_mapping)\n",
    "    \n",
    "    # Add required columns if missing\n",
    "    required_columns = ['Req Set', 'Id'] + list(column_mapping.values())\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = ''\n",
    "            \n",
    "    # Generate sequential IDs if not present\n",
    "    if 'Id' in df.columns and df['Id'].isna().all():\n",
    "        df['Id'] = range(1, len(df) + 1)\n",
    "        \n",
    "    df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_clients():\n",
    "    \"\"\"Initialize clients for LLM service\"\"\"\n",
    "    try:\n",
    "        # Claude setup\n",
    "        verify_path = CERT_PATH if os.path.exists(CERT_PATH) else True\n",
    "        http_client = httpx.Client(verify=verify_path, timeout=60.0)\n",
    "        claude_client = Anthropic(\n",
    "            api_key=os.getenv('ANTHROPIC_API_KEY'),\n",
    "            http_client=http_client\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"claude\": claude_client,\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error setting up clients: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def process_all_content(api_type: str, base_directory: str) -> Dict[str, Any]:\n",
    "    \"\"\"Process all content and generate requirements in Inferno format\"\"\"\n",
    "    clients = setup_clients()\n",
    "    client = clients[api_type]\n",
    "    config = API_CONFIGS[api_type]\n",
    "    rate_limiter = create_rate_limiter()\n",
    "    \n",
    "    def check_limits():\n",
    "        check_rate_limits(rate_limiter, api_type)\n",
    "    \n",
    "    try:\n",
    "        # Process JSON files\n",
    "        json_files = copy_json_files()\n",
    "        all_requirements = []\n",
    "        \n",
    "        for json_file in json_files:\n",
    "            json_data = prepare_json_for_processing(\n",
    "                os.path.join(base_directory, 'json_only', json_file)\n",
    "            )\n",
    "            chunks = split_json(json_data)\n",
    "            \n",
    "            for chunk in chunks:\n",
    "                response = make_api_request(client, api_type, chunk, check_limits)\n",
    "                chunk_requirements = process_llm_requirements_output(response)\n",
    "                all_requirements.extend(chunk_requirements)\n",
    "                time.sleep(config[\"delay_between_chunks\"])\n",
    "                \n",
    "        # Process markdown files\n",
    "        markdown_dir = os.path.join(base_directory, 'markdown')\n",
    "        if os.path.exists(markdown_dir):\n",
    "            for md_file in os.listdir(markdown_dir):\n",
    "                if md_file.endswith('.md'):\n",
    "                    with open(os.path.join(markdown_dir, md_file), 'r') as f:\n",
    "                        content = clean_markdown(f.read())\n",
    "                    chunks = split_markdown(content)\n",
    "                    \n",
    "                    for chunk in chunks:\n",
    "                        response = make_api_request(client, api_type, chunk, check_limits)\n",
    "                        chunk_requirements = process_llm_requirements_output(response)\n",
    "                        all_requirements.extend(chunk_requirements)\n",
    "                        time.sleep(config[\"delay_between_chunks\"])\n",
    "        \n",
    "        # Save requirements to CSV\n",
    "        output_directory = 'processed_output'\n",
    "        output_file = os.path.join(output_directory, f\"test_requirements_{api_type}.json\")\n",
    "        save_requirements_to_csv(all_requirements, output_file)\n",
    "        \n",
    "        return {\n",
    "            \"requirements\": all_requirements,\n",
    "            \"output_file\": output_file\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing content: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_content_for_api(content: Union[str, dict, list], api_type: str) -> str:\n",
    "    \"\"\"Format content appropriately for each API\"\"\"\n",
    "    \n",
    "    # Create the base requirements extraction prompt\n",
    "    base_prompt = create_requirements_extraction_prompt(content)\n",
    "    \n",
    "    if api_type == \"claude\":\n",
    "        return [{\n",
    "            \"type\": \"text\",\n",
    "            \"text\": base_prompt\n",
    "        }]\n",
    "    \n",
    "    # For other APIs, return just the text\n",
    "    return base_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Processing with claude...\n",
      "INFO:root:Copied 166 JSON files to full-ig/json_only\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:anthropic._base_client:Retrying request to /v1/messages in 48.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:anthropic._base_client:Retrying request to /v1/messages in 0.378805 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:anthropic._base_client:Retrying request to /v1/messages in 0.776616 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:root:Error in claude API request: Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': 'This request would exceed your organization’s rate limit of 80,000 input tokens per minute. For details, refer to: https://docs.anthropic.com/en/api/rate-limits; see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.'}}\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:anthropic._base_client:Retrying request to /v1/messages in 0.398714 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:anthropic._base_client:Retrying request to /v1/messages in 0.761792 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:root:Error in claude API request: Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': 'This request would exceed your organization’s rate limit of 2,500,000 tokens per day. For details, refer to: https://docs.anthropic.com/en/api/rate-limits; see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.'}}\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:anthropic._base_client:Retrying request to /v1/messages in 0.471452 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:anthropic._base_client:Retrying request to /v1/messages in 0.933753 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:root:Error in claude API request: Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': 'This request would exceed your organization’s rate limit of 2,500,000 tokens per day. For details, refer to: https://docs.anthropic.com/en/api/rate-limits; see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.'}}\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:anthropic._base_client:Retrying request to /v1/messages in 0.429206 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:anthropic._base_client:Retrying request to /v1/messages in 0.934049 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:root:Error in claude API request: Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': 'This request would exceed your organization’s rate limit of 2,500,000 tokens per day. For details, refer to: https://docs.anthropic.com/en/api/rate-limits; see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.'}}\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:anthropic._base_client:Retrying request to /v1/messages in 53.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Saved claude results to processed_output/test_requirements_claude.json\n"
     ]
    }
   ],
   "source": [
    "# Define input and output directories\n",
    "base_directory = 'full-ig'\n",
    "output_directory = 'processed_output'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Process with each API\n",
    "apis = [\"claude\"]\n",
    "results = {}\n",
    "\n",
    "for api_type in apis:\n",
    "    logging.info(f\"Processing with {api_type}...\")\n",
    "    results[api_type] = process_all_content(api_type, base_directory)\n",
    "    \n",
    "    # Save results\n",
    "    output_file = os.path.join(output_directory, f\"test_requirements_{api_type}.json\")\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(results[api_type], f, indent=2)\n",
    "    logging.info(f\"Saved {api_type} results to {output_file}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
