{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FHIR Test Kit Generator\n",
    "\n",
    "This notebook generates a consolidated test kit markdown file from FHIR Implementation Guide requirements. The output serves as a complete specification that can be used by an LLM to generate executable test scripts.\n",
    "\n",
    "#### What it does\n",
    "\n",
    "- Processes each requirement from a markdown input file\n",
    "- Generates comprehensive test specifications including:\n",
    "  - Testability assessment (Automatic/Manual/Hybrid)\n",
    "  - Implementation strategy with specific FHIR operations\n",
    "  - Required test data and validation criteria\n",
    "  - Implementable pseudocode\n",
    "  - Edge cases and considerations\n",
    "- Creates a single, well-structured markdown file with a table of contents\n",
    "\n",
    "#### How to use\n",
    "\n",
    "1. **Setup**: Individual cert setup may need to be modified in `setup_clients()` function. API keys should be in .env file. Make sure you have API keys for at least one of:\n",
    "   - Anthropic Claude (`ANTHROPIC_API_KEY`)\n",
    "   - Google Gemini (`GEMINI_API_KEY`) \n",
    "   - OpenAI GPT-4 (`OPENAI_API_KEY`)\n",
    "\n",
    "2. **Input**: A markdown file with requirements in the following format:\n",
    "   ```markdown\n",
    "   # REQ-ID\n",
    "   **Summary**: Requirement summary\n",
    "   **Description**: Detailed description\n",
    "   **Verification**: Test approach\n",
    "   **Actor**: System component responsible\n",
    "   **Conformance**: SHALL/SHOULD/MAY\n",
    "   **Conditional**: True/False\n",
    "   **Source**: Original requirement sources\n",
    "   ---\n",
    "   ```\n",
    "\n",
    "3. **Run**: Execute the `run_test_kit_generator()` function and follow the prompts:\n",
    "   - Select which LLM to use\n",
    "   - Provide the path to your requirements file\n",
    "   - Enter the Implementation Guide name\n",
    "   - Specify the output directory, or use the default\n",
    "\n",
    "4. **Output**: A single markdown file will be generated with the format:\n",
    "   `[ig_name]_[llm]_test_kit_[timestamp].md`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic, RateLimitError\n",
    "import google.generativeai as gemini\n",
    "from openai import OpenAI\n",
    "from tenacity import retry, wait_exponential, stop_after_attempt, retry_if_exception_type\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "PROJECT_ROOT = Path.cwd().parent  # Go up one level to project root\n",
    "OUTPUT_DIR = os.path.join(PROJECT_ROOT, '/reqs_extraction/test_plan_output')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# API Configuration\n",
    "API_CONFIGS = {\n",
    "    \"claude\": {\n",
    "        \"model_name\": \"claude-3-7-sonnet-20250219\", \n",
    "        \"max_tokens\": 8192,\n",
    "        \"temperature\": 0.3,  # Lower temperature for more consistent output\n",
    "        \"batch_size\": 5,\n",
    "        \"delay_between_chunks\": 1,\n",
    "        \"delay_between_batches\": 3,\n",
    "        \"requests_per_minute\": 900,\n",
    "        \"max_requests_per_day\": 20000,\n",
    "        \"delay_between_requests\": 0.1\n",
    "    },\n",
    "    \"gemini\": {\n",
    "        \"model\": \"models/gemini-1.5-pro-001\",\n",
    "        \"max_tokens\": 8192,\n",
    "        \"temperature\": 0.3,\n",
    "        \"batch_size\": 5,\n",
    "        \"delay_between_chunks\": 2,\n",
    "        \"delay_between_batches\": 5,\n",
    "        \"requests_per_minute\": 900,\n",
    "        \"max_requests_per_day\": 50000,\n",
    "        \"delay_between_requests\": 0.1,\n",
    "        \"timeout\": 60\n",
    "    },\n",
    "    \"gpt\": {\n",
    "        \"model\": \"gpt-4\",\n",
    "        \"max_tokens\": 3000,\n",
    "        \"temperature\": 0.3,\n",
    "        \"batch_size\": 5,\n",
    "        \"delay_between_chunks\": 2,\n",
    "        \"delay_between_batches\": 5,\n",
    "        \"requests_per_minute\": 450,\n",
    "        \"max_requests_per_day\": 20000,\n",
    "        \"delay_between_requests\": 0.15\n",
    "    }\n",
    "}\n",
    "\n",
    "# System prompts for test generation\n",
    "SYSTEM_PROMPT = \"\"\"You are a specialized FHIR testing engineer with expertise in healthcare interoperability.\n",
    "Your task is to analyze FHIR Implementation Guide requirements and generate practical, implementable test specifications.\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main prompt for consolidated test kit\n",
    "CONSOLIDATED_TEST_KIT_PROMPT = \"\"\"\n",
    "Analyze the following FHIR Implementation Guide requirement and create a comprehensive test specification.\n",
    "\n",
    "For the requirement:\n",
    "{requirement}\n",
    "\n",
    "Create a structured test specification with the following sections:\n",
    "\n",
    "1. Requirement Analysis:\n",
    "   - Testability Assessment: Classify as Automatic, Manual, or Hybrid\n",
    "   - Complexity: Simple, Moderate, or Complex\n",
    "   - Prerequisites: Required system configurations, data, or setup\n",
    "\n",
    "2. Test Implementation Strategy:\n",
    "   - Required FHIR Operations: List specific API calls/operations needed\n",
    "   - Test Data Requirements: Define specific test data needed\n",
    "   - Validation Criteria: Specific checks to verify conformance\n",
    "   \n",
    "3. Pseudocode Implementation:\n",
    "   - Provide detailed, implementable pseudocode that could be directly translated to a test script\n",
    "   - Handle both positive and negative test cases where applicable\n",
    "   - Include proper error handling and edge cases\n",
    "\n",
    "4. Potential Issues and Edge Cases:\n",
    "   - Identify corner cases that should be tested\n",
    "   - Note performance or security considerations\n",
    "\n",
    "Format your response as markdown with clear headers and code blocks for pseudocode.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rate_limiter():\n",
    "    \"\"\"Create a rate limiter state dictionary for all APIs\"\"\"\n",
    "    return {\n",
    "        api: {\n",
    "            'requests': [],\n",
    "            'daily_requests': 0,\n",
    "            'last_reset': time.time()\n",
    "        }\n",
    "        for api in API_CONFIGS.keys()\n",
    "    }\n",
    "\n",
    "def check_rate_limits(rate_limiter: dict, api: str):\n",
    "    \"\"\"Check and wait if rate limits would be exceeded\"\"\"\n",
    "    if api not in rate_limiter:\n",
    "        raise ValueError(f\"Unknown API: {api}\")\n",
    "        \n",
    "    now = time.time()\n",
    "    state = rate_limiter[api]\n",
    "    config = API_CONFIGS[api]\n",
    "    \n",
    "    # Reset daily counts if needed\n",
    "    day_seconds = 24 * 60 * 60\n",
    "    if now - state['last_reset'] >= day_seconds:\n",
    "        state['daily_requests'] = 0\n",
    "        state['last_reset'] = now\n",
    "    \n",
    "    # Check daily limit\n",
    "    if state['daily_requests'] >= config['max_requests_per_day']:\n",
    "        raise Exception(f\"{api} daily request limit exceeded\")\n",
    "    \n",
    "    # Remove old requests outside the current minute\n",
    "    state['requests'] = [\n",
    "        req_time for req_time in state['requests']\n",
    "        if now - req_time < 60\n",
    "    ]\n",
    "    \n",
    "    # Wait if at rate limit\n",
    "    if len(state['requests']) >= config['requests_per_minute']:\n",
    "        sleep_time = 60 - (now - state['requests'][0])\n",
    "        if sleep_time > 0:\n",
    "            time.sleep(sleep_time)\n",
    "        state['requests'] = state['requests'][1:] \n",
    "    \n",
    "    # Add minimum delay between requests\n",
    "    if state['requests'] and now - state['requests'][-1] < config['delay_between_requests']:\n",
    "        time.sleep(config['delay_between_requests'])\n",
    "    \n",
    "    # Record this request\n",
    "    state['requests'].append(now)\n",
    "    state['daily_requests'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_clients():\n",
    "    \"\"\"Initialize clients for each LLM service\"\"\"\n",
    "    try:\n",
    "        # Claude setup\n",
    "        claude_client = Anthropic(\n",
    "            api_key=os.getenv('ANTHROPIC_API_KEY'),\n",
    "        )\n",
    "        \n",
    "        # Gemini setup\n",
    "        gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
    "        if not gemini_api_key:\n",
    "            raise ValueError(\"GEMINI_API_KEY not found\")\n",
    "        gemini.configure(api_key=gemini_api_key)\n",
    "        gemini_client = gemini.GenerativeModel(\n",
    "            model_name=API_CONFIGS[\"gemini\"][\"model\"],\n",
    "            generation_config={\n",
    "                \"max_output_tokens\": API_CONFIGS[\"gemini\"][\"max_tokens\"],\n",
    "                \"temperature\": API_CONFIGS[\"gemini\"][\"temperature\"]\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # OpenAI setup\n",
    "        openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "        if not openai_api_key:\n",
    "            raise ValueError(\"OPENAI_API_KEY not found\")\n",
    "        openai_client = OpenAI(\n",
    "            api_key=openai_api_key,\n",
    "            timeout=60.0\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"claude\": claude_client,\n",
    "            \"gpt\": openai_client,\n",
    "            \"gemini\": gemini_client\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error setting up clients: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_requirements_file(file_path: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Parse an INCOSE requirements markdown file into a structured list of requirements\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the requirements markdown file\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries containing structured requirement information\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Split by requirement sections (separated by ---)\n",
    "    req_sections = content.split('---')\n",
    "    \n",
    "    requirements = []\n",
    "    for section in req_sections:\n",
    "        if not section.strip():\n",
    "            continue\n",
    "            \n",
    "        # Parse requirement data\n",
    "        req_data = {}\n",
    "        \n",
    "        # Extract ID from format \"# REQ-XXX-XXX-XX\"\n",
    "        id_match = re.search(r'#\\s+([A-Z0-9\\-]+)', section)\n",
    "        if id_match:\n",
    "            req_data['id'] = id_match.group(1)\n",
    "        \n",
    "        # Extract other fields\n",
    "        for field in ['Summary', 'Description', 'Verification', 'Actor', 'Conformance', 'Conditional', 'Source']:\n",
    "            pattern = rf'\\*\\*{field}\\*\\*:\\s*(.*?)(?:\\n\\*\\*|\\n---|\\\\Z)'\n",
    "            field_match = re.search(pattern, section, re.DOTALL)\n",
    "            if field_match:\n",
    "                req_data[field.lower()] = field_match.group(1).strip()\n",
    "        \n",
    "        if req_data:\n",
    "            requirements.append(req_data)\n",
    "    \n",
    "    return requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_requirement_for_prompt(requirement: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    Format a requirement dictionary into markdown for inclusion in prompts\n",
    "    \n",
    "    Args:\n",
    "        requirement: Requirement dictionary\n",
    "        \n",
    "    Returns:\n",
    "        Formatted markdown string\n",
    "    \"\"\"\n",
    "    formatted = f\"# {requirement.get('id', 'UNKNOWN-ID')}\\n\"\n",
    "    formatted += f\"**Summary**: {requirement.get('summary', '')}\\n\"\n",
    "    formatted += f\"**Description**: {requirement.get('description', '')}\\n\"\n",
    "    formatted += f\"**Verification**: {requirement.get('verification', '')}\\n\"\n",
    "    formatted += f\"**Actor**: {requirement.get('actor', '')}\\n\"\n",
    "    formatted += f\"**Conformance**: {requirement.get('conformance', '')}\\n\"\n",
    "    formatted += f\"**Conditional**: {requirement.get('conditional', '')}\\n\"\n",
    "    formatted += f\"**Source**: {requirement.get('source', '')}\\n\"\n",
    "    \n",
    "    return formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(\n",
    "    wait=wait_exponential(multiplier=1, min=4, max=60),\n",
    "    stop=stop_after_attempt(5),\n",
    "    retry=retry_if_exception_type((RateLimitError, TimeoutError))\n",
    ")\n",
    "def make_llm_request(client, api_type: str, prompt: str, rate_limit_func) -> str:\n",
    "    \"\"\"Make rate-limited API request with retries\"\"\"\n",
    "    rate_limit_func()\n",
    "    \n",
    "    config = API_CONFIGS[api_type]\n",
    "    \n",
    "    try:\n",
    "        if api_type == \"claude\":\n",
    "            response = client.messages.create(\n",
    "                model=config[\"model_name\"],\n",
    "                max_tokens=config[\"max_tokens\"],\n",
    "                messages=[{\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": prompt\n",
    "                }],\n",
    "                system=SYSTEM_PROMPT\n",
    "            )\n",
    "            return response.content[0].text\n",
    "            \n",
    "        elif api_type == \"gemini\":\n",
    "            response = client.generate_content(\n",
    "                prompt,\n",
    "                generation_config={\n",
    "                    \"max_output_tokens\": config[\"max_tokens\"],\n",
    "                    \"temperature\": config[\"temperature\"]\n",
    "                }\n",
    "            )\n",
    "            if hasattr(response, 'text'):\n",
    "                return response.text\n",
    "            elif response.candidates:\n",
    "                return response.candidates[0].content.parts[0].text\n",
    "            else:\n",
    "                raise ValueError(\"No response generated from Gemini API\")\n",
    "                    \n",
    "        elif api_type == \"gpt\":\n",
    "            response = client.chat.completions.create(\n",
    "                model=config[\"model\"],\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                max_tokens=config[\"max_tokens\"],\n",
    "                temperature=config[\"temperature\"]\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "            \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in {api_type} API request: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_specification(\n",
    "    client, \n",
    "    api_type: str,\n",
    "    requirement: Dict[str, str],\n",
    "    rate_limit_func\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate a comprehensive test specification for a single requirement\n",
    "    \n",
    "    Args:\n",
    "        client: The API client\n",
    "        api_type: API type (claude, gemini, gpt)\n",
    "        requirement: Requirement dictionary\n",
    "        rate_limit_func: Function to check rate limits\n",
    "        \n",
    "    Returns:\n",
    "        Test specification for the requirement\n",
    "    \"\"\"\n",
    "    logger.info(f\"Generating test specification for {requirement.get('id', 'unknown')} using {api_type}...\")\n",
    "    \n",
    "    # Format requirement as markdown\n",
    "    formatted_req = format_requirement_for_prompt(requirement)\n",
    "    \n",
    "    # Create prompt with the requirement\n",
    "    prompt = CONSOLIDATED_TEST_KIT_PROMPT.format(requirement=formatted_req)\n",
    "    \n",
    "    # Make the API request\n",
    "    return make_llm_request(client, api_type, prompt, rate_limit_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_consolidated_test_kit(\n",
    "    api_type: str,\n",
    "    requirements_file: str,\n",
    "    ig_name: str = \"FHIR Implementation Guide\",\n",
    "    output_dir: str = OUTPUT_DIR\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Process requirements and generate a consolidated test kit\n",
    "    \n",
    "    Args:\n",
    "        api_type: API type (claude, gemini, gpt)\n",
    "        requirements_file: Path to requirements markdown file\n",
    "        ig_name: Name of the Implementation Guide\n",
    "        output_dir: Directory for output files\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing path to output file\n",
    "    \"\"\"\n",
    "    logger.info(f\"Starting test kit generation with {api_type} for {ig_name}\")\n",
    "    \n",
    "    # Initialize API clients and rate limiters\n",
    "    clients = setup_clients()\n",
    "    client = clients[api_type]\n",
    "    config = API_CONFIGS[api_type]\n",
    "    rate_limiter = create_rate_limiter()\n",
    "    \n",
    "    def check_limits():\n",
    "        check_rate_limits(rate_limiter, api_type)\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    try:\n",
    "        # Parse requirements from file\n",
    "        requirements = parse_requirements_file(requirements_file)\n",
    "        logger.info(f\"Parsed {len(requirements)} requirements from {requirements_file}\")\n",
    "        \n",
    "        # Output file\n",
    "        test_kit_path = os.path.join(\n",
    "            output_dir, \n",
    "            f\"{ig_name.lower().replace(' ', '_')}_{api_type}_test_kit_{timestamp}.md\"\n",
    "        )\n",
    "        \n",
    "        # Initialize test kit content\n",
    "        test_kit = f\"# Consolidated Test Kit for {ig_name}\\n\\n\"\n",
    "        test_kit += f\"## Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\"\n",
    "        test_kit += \"## Table of Contents\\n\\n\"\n",
    "        \n",
    "        # Add table of contents\n",
    "        for req in requirements:\n",
    "            req_id = req.get('id', 'UNKNOWN-ID')\n",
    "            req_summary = req.get('summary', 'No summary')\n",
    "            test_kit += f\"- [{req_id}: {req_summary}](#{req_id.lower()})\\n\"\n",
    "        \n",
    "        test_kit += \"\\n## Test Specifications\\n\\n\"\n",
    "        \n",
    "        # Process each requirement\n",
    "        for i, req in enumerate(requirements):\n",
    "            req_id = req.get('id', 'UNKNOWN-ID')\n",
    "            logger.info(f\"Processing requirement {i+1}/{len(requirements)}: {req_id}\")\n",
    "            \n",
    "            # Generate test specification\n",
    "            test_spec = generate_test_specification(client, api_type, req, check_limits)\n",
    "            \n",
    "            # Add to test kit content with proper anchor for TOC linking\n",
    "            test_kit += f\"<a id='{req_id.lower()}'></a>\\n\\n\"\n",
    "            test_kit += f\"### {req_id}: {req.get('summary', 'No summary')}\\n\\n\"\n",
    "            test_kit += f\"**Description**: {req.get('description', '')}\\n\\n\"\n",
    "            test_kit += f\"**Actor**: {req.get('actor', '')}\\n\\n\"\n",
    "            test_kit += f\"**Conformance**: {req.get('conformance', '')}\\n\\n\"\n",
    "            test_kit += f\"{test_spec}\\n\\n\"\n",
    "            test_kit += \"---\\n\\n\"\n",
    "            \n",
    "            # Add delay between requests\n",
    "            if i < len(requirements) - 1:  # No need to delay after the last request\n",
    "                time.sleep(config[\"delay_between_chunks\"])\n",
    "        \n",
    "        # Save consolidated test kit\n",
    "        with open(test_kit_path, 'w') as f:\n",
    "            f.write(test_kit)\n",
    "        logger.info(f\"Consolidated test kit saved to {test_kit_path}\")\n",
    "        \n",
    "        return {\n",
    "            \"requirements_count\": len(requirements),\n",
    "            \"test_kit_path\": test_kit_path\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing requirements: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive notebook cell for running the generator\n",
    "def run_test_kit_generator():\n",
    "    # Load environment variables\n",
    "    load_dotenv()\n",
    "    \n",
    "    # Get input from user or set default values\n",
    "    print(\"\\nFHIR IG Test Kit Generator\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Let user select the API\n",
    "    print(\"\\nSelect the API to use:\")\n",
    "    print(\"1. Claude\")\n",
    "    print(\"2. Gemini\")\n",
    "    print(\"3. GPT-4\")\n",
    "    api_choice = input(\"Enter your choice (1-3, default 1): \") or \"1\"\n",
    "    \n",
    "    api_mapping = {\n",
    "        \"1\": \"claude\",\n",
    "        \"2\": \"gemini\",\n",
    "        \"3\": \"gpt\"\n",
    "    }\n",
    "    \n",
    "    api_type = api_mapping.get(api_choice, \"claude\")\n",
    "    \n",
    "    # Get requirements file path\n",
    "    requirements_file = input(\"\\nEnter path to requirements markdown file: \")\n",
    "    \n",
    "    # Check if requirements file exists\n",
    "    if not os.path.exists(requirements_file):\n",
    "        logger.error(f\"Requirements file not found: {requirements_file}\")\n",
    "        print(f\"Error: Requirements file not found at {requirements_file}\")\n",
    "        return\n",
    "    \n",
    "    # Get IG name\n",
    "    ig_name = input(\"\\nEnter Implementation Guide name (default 'FHIR Implementation Guide'): \") or \"FHIR Implementation Guide\"\n",
    "    \n",
    "    # Get output directory\n",
    "    output_dir = input(f\"\\nEnter output directory (default '{OUTPUT_DIR}'): \") or OUTPUT_DIR\n",
    "    \n",
    "    print(f\"\\nProcessing requirements with {api_type.capitalize()}...\")\n",
    "    print(f\"This may take several minutes depending on the number of requirements.\")\n",
    "    \n",
    "    try:\n",
    "        # Process requirements and generate test kit\n",
    "        result = generate_consolidated_test_kit(\n",
    "            api_type=api_type,\n",
    "            requirements_file=requirements_file,\n",
    "            ig_name=ig_name,\n",
    "            output_dir=output_dir\n",
    "        )\n",
    "        \n",
    "        # Output results\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"Test kit generation complete!\")\n",
    "        print(f\"Processed {result['requirements_count']} requirements\")\n",
    "        print(f\"Consolidated test kit: {result['test_kit_path']}\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error: {str(e)}\")\n",
    "        print(f\"\\nError occurred during processing: {str(e)}\")\n",
    "        print(\"Check the log for more details.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FHIR IG Test Kit Generator\n",
      "==================================================\n",
      "\n",
      "Select the API to use:\n",
      "1. Claude\n",
      "2. Gemini\n",
      "3. GPT-4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 12:50:12,356 - __main__ - INFO - Starting test kit generation with gpt for Plan Net\n",
      "2025-03-19 12:50:12,371 - __main__ - INFO - Parsed 18 requirements from /Users/ceadams/Documents/onclaive/onclaive/reqs_extraction/revised_reqs/refined_requirements_gemini_20250319_114029.md\n",
      "2025-03-19 12:50:12,371 - __main__ - INFO - Processing requirement 1/18: R\n",
      "2025-03-19 12:50:12,372 - __main__ - INFO - Generating test specification for R using gpt...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing requirements with Gpt...\n",
      "This may take several minutes depending on the number of requirements.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 12:50:35,776 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-19 12:50:37,798 - __main__ - INFO - Processing requirement 2/18: REQ-AUTH-01\n",
      "2025-03-19 12:50:37,799 - __main__ - INFO - Generating test specification for REQ-AUTH-01 using gpt...\n",
      "2025-03-19 12:50:55,873 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-19 12:50:57,885 - __main__ - INFO - Processing requirement 3/18: REQ-CLIENT-01\n",
      "2025-03-19 12:50:57,886 - __main__ - INFO - Generating test specification for REQ-CLIENT-01 using gpt...\n",
      "2025-03-19 12:51:14,861 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-19 12:51:16,868 - __main__ - INFO - Processing requirement 4/18: REQ-DATA-01\n",
      "2025-03-19 12:51:16,869 - __main__ - INFO - Generating test specification for REQ-DATA-01 using gpt...\n",
      "2025-03-19 12:51:35,598 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-19 12:51:37,604 - __main__ - INFO - Processing requirement 5/18: REQ-DATA-02\n",
      "2025-03-19 12:51:37,605 - __main__ - INFO - Generating test specification for REQ-DATA-02 using gpt...\n",
      "2025-03-19 12:51:58,437 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-19 12:52:00,446 - __main__ - INFO - Processing requirement 6/18: REQ-DATA-03\n",
      "2025-03-19 12:52:00,448 - __main__ - INFO - Generating test specification for REQ-DATA-03 using gpt...\n",
      "2025-03-19 12:52:20,874 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-19 12:52:22,880 - __main__ - INFO - Processing requirement 7/18: REQ-CLIENT-02\n",
      "2025-03-19 12:52:22,881 - __main__ - INFO - Generating test specification for REQ-CLIENT-02 using gpt...\n",
      "2025-03-19 12:52:44,078 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-19 12:52:46,089 - __main__ - INFO - Processing requirement 8/18: REQ-CLIENT-03\n",
      "2025-03-19 12:52:46,090 - __main__ - INFO - Generating test specification for REQ-CLIENT-03 using gpt...\n",
      "2025-03-19 12:53:02,947 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-19 12:53:04,950 - __main__ - INFO - Processing requirement 9/18: REQ-CLIENT-04\n",
      "2025-03-19 12:53:04,951 - __main__ - INFO - Generating test specification for REQ-CLIENT-04 using gpt...\n",
      "2025-03-19 12:53:28,795 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-19 12:53:30,822 - __main__ - INFO - Processing requirement 10/18: REQ-CLIENT-05\n",
      "2025-03-19 12:53:30,822 - __main__ - INFO - Generating test specification for REQ-CLIENT-05 using gpt...\n",
      "2025-03-19 12:53:56,145 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-19 12:53:58,159 - __main__ - INFO - Processing requirement 11/18: REQ-CACHE-01\n",
      "2025-03-19 12:53:58,160 - __main__ - INFO - Generating test specification for REQ-CACHE-01 using gpt...\n",
      "2025-03-19 12:54:22,145 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-19 12:54:24,157 - __main__ - INFO - Processing requirement 12/18: REQ-RESOURCE-01\n",
      "2025-03-19 12:54:24,158 - __main__ - INFO - Generating test specification for REQ-RESOURCE-01 using gpt...\n",
      "2025-03-19 12:54:48,088 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-19 12:54:50,103 - __main__ - INFO - Processing requirement 13/18: REQ-RESOURCE-02\n",
      "2025-03-19 12:54:50,103 - __main__ - INFO - Generating test specification for REQ-RESOURCE-02 using gpt...\n",
      "2025-03-19 12:55:11,347 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-19 12:55:13,352 - __main__ - INFO - Processing requirement 14/18: REQ-RESOURCE-03\n",
      "2025-03-19 12:55:13,353 - __main__ - INFO - Generating test specification for REQ-RESOURCE-03 using gpt...\n",
      "2025-03-19 12:55:32,667 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-19 12:55:34,678 - __main__ - INFO - Processing requirement 15/18: REQ-SERVER-01\n",
      "2025-03-19 12:55:34,678 - __main__ - INFO - Generating test specification for REQ-SERVER-01 using gpt...\n",
      "2025-03-19 12:55:58,568 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-19 12:56:00,574 - __main__ - INFO - Processing requirement 16/18: REQ-SERVER-02\n",
      "2025-03-19 12:56:00,582 - __main__ - INFO - Generating test specification for REQ-SERVER-02 using gpt...\n",
      "2025-03-19 12:56:28,300 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-19 12:56:30,310 - __main__ - INFO - Processing requirement 17/18: REQ-SERVER-03\n",
      "2025-03-19 12:56:30,310 - __main__ - INFO - Generating test specification for REQ-SERVER-03 using gpt...\n",
      "2025-03-19 12:56:49,795 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-19 12:56:51,814 - __main__ - INFO - Processing requirement 18/18: REQ-SERVER-04\n",
      "2025-03-19 12:56:51,815 - __main__ - INFO - Generating test specification for REQ-SERVER-04 using gpt...\n",
      "2025-03-19 12:57:10,776 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-19 12:57:10,782 - __main__ - INFO - Consolidated test kit saved to /Users/ceadams/Documents/onclaive/onclaive/reqs_extraction/test_plan_output/plan_net_gpt_test_kit_20250319_125012.md\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Test kit generation complete!\n",
      "Processed 18 requirements\n",
      "Consolidated test kit: /Users/ceadams/Documents/onclaive/onclaive/reqs_extraction/test_plan_output/plan_net_gpt_test_kit_20250319_125012.md\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Run the generator when executed in a notebook cell\n",
    "if __name__ == \"__main__\":\n",
    "    run_test_kit_generator()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
